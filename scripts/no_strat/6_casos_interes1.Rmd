---
title: "Casos de interés"
author: "Juan Baeza Ruiz-Henestrosa"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(tidyverse)
library(tidymodels)
library(sf)
library(ggplot2)
library(terra)
```

```{r}
load("salidas_intermedias/datos_depurados_geom_2024-04-23.RData")

```


Para poder estudiar casos concretos de interés, sin tener que hacer frente a todas las complicaciones derivadas del trabajar con datos raster, un enfoque puede ser el siguiente:
1. Estudiar un incendio concreto un día y ver como evoluciona el riesgo de incendio en los días cercanos, en el área de interés (un área que contenga al incendio que se quiere estudiar).

2. Generar puntos aleatoriamente en el área de interés (o formando una cuadrícula) en cada uno de los días cercanos al incendio. 

3. Asociar a cada punto sus variables correspondientes siguiendo el procedimiento usado para generar la muestra.

4. Usar el modelo para clasificar cada punto (o predecir la probabilidad de incendio).

5. Mostrar los gráficos de cada día con el polígono del incendio y compararlos para estudiar la capacidad de discretización del modelo.

6. En función del rendimiento del modelo se puede probar a extender el área de estudio y usar instantes de tiempo más alejados entre sí (p.e. semanas), pues es razonable que en días próximos y localizaciones cercanas los riesgos no varíen en exceso.

Si se obtienen resultados razonables, puede probarse a añadir variaciones en las variables climáticas (p.e. temperatura) para ver sus efectos.



```{r}
set.seed(123)

datos = datos %>% st_drop_geometry() %>%  dplyr::select(fire,elevacion,curvatura,pendiente)

splits = initial_validation_time_split(datos, 
                                       prop=c(0.6,0.2))

training <- training(splits) %>%  st_drop_geometry()
val_set <- validation_set(splits) %>% st_drop_geometry()
test  <- testing(splits) %>% st_drop_geometry()

```
La idea será coger uno de los modelos entrenados y ver qué predicciones da para un día concreto y compararlo con lo que ocurrió ese día

```{r}
#2º definimos el modelo
lr_mod <- 
  logistic_reg(penalty = NULL, mixture = NULL) %>% 
  set_engine("glm")

# 3º Creamos la receta
# holidays <- c("AllSouls", "AshWednesday", "ChristmasEve", "Easter", 
#               "ChristmasDay", "GoodFriday", "NewYearsDay", "PalmSunday")

lr_recipe <- 
  recipe(fire ~ ., data = training) %>% 
#  step_date(date,features = c("dow", "month")) %>% 
  # step_holiday(date, holidays = holidays) %>% 
#  step_rm(date,cod_municipio,municipio) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_zv(all_predictors()) %>% 
  step_normalize(all_predictors())

# 4º Creamos el workflow
lr_workflow <- 
  workflow() %>% 
  add_model(lr_mod) %>% 
  add_recipe(lr_recipe)

# 5º Ajustamos el modelo.
lr_res <- 
  lr_workflow %>% 
  fit(training)


pred = cbind(predict(lr_res,new_data = validation(splits),type="prob"),
             predict(lr_res,new_data = validation(splits),type="class"),
             fire = validation(splits)$fire)
pred

# 6º Se evalúa el modelo:
#   Curva ROC
lr_auc <- pred %>% 
  roc_curve(fire, .pred_0) %>% 
  mutate(model = "Logistic Regression")

autoplot(lr_auc)


#   Medidas de rendimiento
get_metrics <- function(pred) {
  list(
    res = tibble(
      roc_auc = pred |> roc_auc(truth = fire, .pred_0) |> pull(.estimate),
      accuracy = pred |> accuracy(truth = fire, .pred_class) |> pull(.estimate),
      recall = pred |> sensitivity(truth = fire, .pred_class) |> pull(.estimate),
      specificity = pred |> spec(truth = fire, .pred_class) |> pull(.estimate)),
    conf_mat = pred |> conf_mat(truth = fire, .pred_class))
}
lr_metrics <- pred |> 
  get_metrics()

lr_metrics
```

```{r}
# Construir raster

elevacion <- rast("data_raw/topograficas/elevacion.tif") %>% as.numeric()
pendiente <- rast("data_raw/topograficas/pendiente.tif") %>% as.numeric() 
orientacion <- rast("data_raw/topograficas/orientacion.tif") %>% as.numeric()
curvatura <- rast("data_raw/topograficas/curvatura.tif") %>% as.numeric()

# Codificar orientacion
orientacion[] = cut(orientacion[],
                           breaks = c(-Inf,-1,22.5,67.5,112.5,157.5,202.5,247.5,292.5,337.5,360),
                           labels = c("Plano","N","NE","E","SE","S","SW","W","NW","N"))


# Resamplear para que coincidan los los ráster pixel a pixel, se usa de modelo, elevacion

pendiente = project(pendiente, elevacion) %>% resample(elevacion)
orientacion = project(orientacion, elevacion) %>% resample(elevacion)
curvatura = project(curvatura, elevacion) %>% resample(elevacion)

newdata = c(elevacion,pendiente,curvatura)

names(newdata)  = c("elevacion","pendiente","curvatura")
  
```

