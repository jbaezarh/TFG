\documentclass[12pt,a4paper,]{book}
\def\ifdoblecara{} %% set to true
\def\ifprincipal{} %% set to true
\let\ifprincipal\undefined %% set to false
\def\ifcitapandoc{} %% set to true
\let\ifcitapandoc\undefined %% set to false
\usepackage{lmodern}
% sin fontmathfamily
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
%\usepackage{fixltx2e} % provides \textsubscript %PLLC
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin = 2.5cm]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdfauthor={Nombre Completo Autor},
              pdfborder={0 0 0},
              breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
%
\usepackage[usenames,dvipsnames]{xcolor}  %new PLLC
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}


  \title{}
    \author{Nombre Completo Autor}
      \date{18/11/2021}


%%%%%%% inicio: latex_preambulo.tex PLLC


%% UTILIZA CODIFICACIÓN UTF-8
%% MODIFICARLO CONVENIENTEMENTE PARA USARLO CON OTRAS CODIFICACIONES


%\usepackage[spanish,es-nodecimaldot,es-noshorthands]{babel}
\usepackage[spanish,es-nodecimaldot,es-noshorthands,es-tabla]{babel}
% Ver: es-tabla (en: https://osl.ugr.es/CTAN/macros/latex/contrib/babel-contrib/spanish/spanish.pdf)
% es-tabla (en: https://tex.stackexchange.com/questions/80443/change-the-word-table-in-table-captions)
\usepackage[spanish, plain, datebegin,sortcompress,nocomment,
noabstract]{flexbib}
 
\usepackage{float}
\usepackage{placeins}
\usepackage{fancyhdr}
% Solucion: ! LaTeX Error: Command \counterwithout already defined.
% https://tex.stackexchange.com/questions/425600/latex-error-command-counterwithout-already-defined
\let\counterwithout\relax
\let\counterwithin\relax
\usepackage{chngcntr}
%\usepackage{microtype}  %antes en template PLLC
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc} % Usa codificación 8-bit que tiene 256 glyphs

%\usepackage[dvipsnames]{xcolor}
%\usepackage[usenames,dvipsnames]{xcolor}  %new
\usepackage{pdfpages}
%\usepackage{natbib}




% Para portada: latex_paginatitulo_mod_ST02.tex (inicio)
\usepackage{tikz}
\usepackage{epigraph}
\input{portadas/latex_paginatitulo_mod_ST02_add.sty}
% Para portada: latex_paginatitulo_mod_ST02.tex (fin)

% Para portada: latex_paginatitulo_mod_OV01.tex (inicio)
\usepackage{cpimod}
% Para portada: latex_paginatitulo_mod_OV01.tex (fin)

% Para portada: latex_paginatitulo_mod_OV03.tex (inicio)
\usepackage{KTHEEtitlepage}
% Para portada: latex_paginatitulo_mod_OV03.tex (fin)

\renewcommand{\contentsname}{Índice}
\renewcommand{\listfigurename}{Índice de figuras}
\renewcommand{\listtablename}{Índice de tablas}
\newcommand{\bcols}{}
\newcommand{\ecols}{}
\newcommand{\bcol}[1]{\begin{minipage}{#1\linewidth}}
\newcommand{\ecol}{\end{minipage}}
\newcommand{\balertblock}[1]{\begin{alertblock}{#1}}
\newcommand{\ealertblock}{\end{alertblock}}
\newcommand{\bitemize}{\begin{itemize}}
\newcommand{\eitemize}{\end{itemize}}
\newcommand{\benumerate}{\begin{enumerate}}
\newcommand{\eenumerate}{\end{enumerate}}
\newcommand{\saltopagina}{\newpage}
\newcommand{\bcenter}{\begin{center}}
\newcommand{\ecenter}{\end{center}}
\newcommand{\beproof}{\begin{proof}} %new
\newcommand{\eeproof}{\end{proof}} %new
%De: https://texblog.org/2007/11/07/headerfooter-in-latex-with-fancyhdr/
% \fancyhead
% E: Even page
% O: Odd page
% L: Left field
% C: Center field
% R: Right field
% H: Header
% F: Footer
%\fancyhead[CO,CE]{Resultados}

%OPCION 1
% \fancyhead[LE,RO]{\slshape \rightmark}
% \fancyhead[LO,RE]{\slshape \leftmark}
% \fancyfoot[C]{\thepage}
% \renewcommand{\headrulewidth}{0.4pt}
% \renewcommand{\footrulewidth}{0pt}

%OPCION 2
% \fancyhead[LE,RO]{\slshape \rightmark}
% \fancyfoot[LO,RE]{\slshape \leftmark}
% \fancyfoot[LE,RO]{\thepage}
% \renewcommand{\headrulewidth}{0.4pt}
% \renewcommand{\footrulewidth}{0.4pt}
%%%%%%%%%%
\usepackage{calc,amsfonts}
% Elimina la cabecera de páginas impares vacías al finalizar los capítulos
\usepackage{emptypage}
\makeatletter

%\definecolor{ocre}{RGB}{25,25,243} % Define el color azul (naranja) usado para resaltar algunas salidas
\definecolor{ocre}{RGB}{0,0,0} % Define el color a negro (aparece en los teoremas

%\usepackage{calc} 


%era if(csl-refs) con dolares
% metodobib: true


\usepackage{lipsum}

%\usepackage{tikz} % Requerido para dibujar formas personalizadas

%\usepackage{amsmath,amsthm,amssymb,amsfonts}
\usepackage{amsthm}


% Boxed/framed environments
\newtheoremstyle{ocrenumbox}% % Theorem style name
{0pt}% Space above
{0pt}% Space below
{\normalfont}% % Body font
{}% Indent amount
{\small\bf\sffamily\color{ocre}}% % Theorem head font
{\;}% Punctuation after theorem head
{0.25em}% Space after theorem head
{\small\sffamily\color{ocre}\thmname{#1}\nobreakspace\thmnumber{\@ifnotempty{#1}{}\@upn{#2}}% Theorem text (e.g. Theorem 2.1)
\thmnote{\nobreakspace\the\thm@notefont\sffamily\bfseries\color{black}---\nobreakspace#3.}} % Optional theorem note
\renewcommand{\qedsymbol}{$\blacksquare$}% Optional qed square

\newtheoremstyle{blacknumex}% Theorem style name
{5pt}% Space above
{5pt}% Space below
{\normalfont}% Body font
{} % Indent amount
{\small\bf\sffamily}% Theorem head font
{\;}% Punctuation after theorem head
{0.25em}% Space after theorem head
{\small\sffamily{\tiny\ensuremath{\blacksquare}}\nobreakspace\thmname{#1}\nobreakspace\thmnumber{\@ifnotempty{#1}{}\@upn{#2}}% Theorem text (e.g. Theorem 2.1)
\thmnote{\nobreakspace\the\thm@notefont\sffamily\bfseries---\nobreakspace#3.}}% Optional theorem note

\newtheoremstyle{blacknumbox} % Theorem style name
{0pt}% Space above
{0pt}% Space below
{\normalfont}% Body font
{}% Indent amount
{\small\bf\sffamily}% Theorem head font
{\;}% Punctuation after theorem head
{0.25em}% Space after theorem head
{\small\sffamily\thmname{#1}\nobreakspace\thmnumber{\@ifnotempty{#1}{}\@upn{#2}}% Theorem text (e.g. Theorem 2.1)
\thmnote{\nobreakspace\the\thm@notefont\sffamily\bfseries---\nobreakspace#3.}}% Optional theorem note

% Non-boxed/non-framed environments
\newtheoremstyle{ocrenum}% % Theorem style name
{5pt}% Space above
{5pt}% Space below
{\normalfont}% % Body font
{}% Indent amount
{\small\bf\sffamily\color{ocre}}% % Theorem head font
{\;}% Punctuation after theorem head
{0.25em}% Space after theorem head
{\small\sffamily\color{ocre}\thmname{#1}\nobreakspace\thmnumber{\@ifnotempty{#1}{}\@upn{#2}}% Theorem text (e.g. Theorem 2.1)
\thmnote{\nobreakspace\the\thm@notefont\sffamily\bfseries\color{black}---\nobreakspace#3.}} % Optional theorem note
\renewcommand{\qedsymbol}{$\blacksquare$}% Optional qed square
\makeatother



% Define el estilo texto theorem para cada tipo definido anteriormente
\newcounter{dummy} 
\numberwithin{dummy}{section}
\theoremstyle{ocrenumbox}
\newtheorem{theoremeT}[dummy]{Teorema}  % (Pedro: Theorem)
\newtheorem{problem}{Problema}[chapter]  % (Pedro: Problem)
\newtheorem{exerciseT}{Ejercicio}[chapter] % (Pedro: Exercise)
\theoremstyle{blacknumex}
\newtheorem{exampleT}{Ejemplo}[chapter] % (Pedro: Example)
\theoremstyle{blacknumbox}
\newtheorem{vocabulary}{Vocabulario}[chapter]  % (Pedro: Vocabulary)
\newtheorem{definitionT}{Definición}[section]  % (Pedro: Definition)
\newtheorem{corollaryT}[dummy]{Corolario}  % (Pedro: Corollary)
\theoremstyle{ocrenum}
\newtheorem{proposition}[dummy]{Proposición} % (Pedro: Proposition)


\usepackage[framemethod=default]{mdframed}



\newcommand{\intoo}[2]{\mathopen{]}#1\,;#2\mathclose{[}}
\newcommand{\ud}{\mathop{\mathrm{{}d}}\mathopen{}}
\newcommand{\intff}[2]{\mathopen{[}#1\,;#2\mathclose{]}}
\newtheorem{notation}{Notation}[chapter]


\mdfdefinestyle{exampledefault}{%
rightline=true,innerleftmargin=10,innerrightmargin=10,
frametitlerule=true,frametitlerulecolor=green,
frametitlebackgroundcolor=yellow,
frametitlerulewidth=2pt}


% Theorem box
\newmdenv[skipabove=7pt,
skipbelow=7pt,
backgroundcolor=black!5,
linecolor=ocre,
innerleftmargin=5pt,
innerrightmargin=5pt,
innertopmargin=10pt,%5pt
leftmargin=0cm,
rightmargin=0cm,
innerbottommargin=5pt]{tBox}

% Exercise box	  
\newmdenv[skipabove=7pt,
skipbelow=7pt,
rightline=false,
leftline=true,
topline=false,
bottomline=false,
backgroundcolor=ocre!10,
linecolor=ocre,
innerleftmargin=5pt,
innerrightmargin=5pt,
innertopmargin=10pt,%5pt
innerbottommargin=5pt,
leftmargin=0cm,
rightmargin=0cm,
linewidth=4pt]{eBox}	

% Definition box
\newmdenv[skipabove=7pt,
skipbelow=7pt,
rightline=false,
leftline=true,
topline=false,
bottomline=false,
linecolor=ocre,
innerleftmargin=5pt,
innerrightmargin=5pt,
innertopmargin=10pt,%0pt
leftmargin=0cm,
rightmargin=0cm,
linewidth=4pt,
innerbottommargin=0pt]{dBox}	

% Corollary box
\newmdenv[skipabove=7pt,
skipbelow=7pt,
rightline=false,
leftline=true,
topline=false,
bottomline=false,
linecolor=gray,
backgroundcolor=black!5,
innerleftmargin=5pt,
innerrightmargin=5pt,
innertopmargin=10pt,%5pt
leftmargin=0cm,
rightmargin=0cm,
linewidth=4pt,
innerbottommargin=5pt]{cBox}

% Crea un entorno para cada tipo de theorem y le asigna un estilo 
% con ayuda de las cajas coloreadas anteriores
\newenvironment{theorem}{\begin{tBox}\begin{theoremeT}}{\end{theoremeT}\end{tBox}}
\newenvironment{exercise}{\begin{eBox}\begin{exerciseT}}{\hfill{\color{ocre}\tiny\ensuremath{\blacksquare}}\end{exerciseT}\end{eBox}}				  
\newenvironment{definition}{\begin{dBox}\begin{definitionT}}{\end{definitionT}\end{dBox}}	
\newenvironment{example}{\begin{exampleT}}{\hfill{\tiny\ensuremath{\blacksquare}}\end{exampleT}}		
\newenvironment{corollary}{\begin{cBox}\begin{corollaryT}}{\end{corollaryT}\end{cBox}}	

%	ENVIRONMENT remark
\newenvironment{remark}{\par\vspace{10pt}\small 
% Espacio blanco vertical sobre la nota y tamaño de fuente menor
\begin{list}{}{
\leftmargin=35pt % Indentación sobre la izquierda
\rightmargin=25pt}\item\ignorespaces % Indentación sobre la derecha
\makebox[-2.5pt]{\begin{tikzpicture}[overlay]
\node[draw=ocre!60,line width=1pt,circle,fill=ocre!25,font=\sffamily\bfseries,inner sep=2pt,outer sep=0pt] at (-15pt,0pt){\textcolor{ocre}{N}}; \end{tikzpicture}} % R naranja en un círculo (Pedro)
\advance\baselineskip -1pt}{\end{list}\vskip5pt} 
% Espaciado de línea más estrecho y espacio en blanco después del comentario


\newenvironment{solutionExe}{\par\vspace{10pt}\small 
\begin{list}{}{
\leftmargin=35pt 
\rightmargin=25pt}\item\ignorespaces 
\makebox[-2.5pt]{\begin{tikzpicture}[overlay]
\node[draw=ocre!60,line width=1pt,circle,fill=ocre!25,font=\sffamily\bfseries,inner sep=2pt,outer sep=0pt] at (-15pt,0pt){\textcolor{ocre}{S}}; \end{tikzpicture}} 
\advance\baselineskip -1pt}{\end{list}\vskip5pt} 

\newenvironment{solutionExa}{\par\vspace{10pt}\small 
\begin{list}{}{
\leftmargin=35pt 
\rightmargin=25pt}\item\ignorespaces 
\makebox[-2.5pt]{\begin{tikzpicture}[overlay]
\node[draw=ocre!60,line width=1pt,circle,fill=ocre!55,font=\sffamily\bfseries,inner sep=2pt,outer sep=0pt] at (-15pt,0pt){\textcolor{ocre}{S}}; \end{tikzpicture}} 
\advance\baselineskip -1pt}{\end{list}\vskip5pt} 

\usepackage{tcolorbox}

\usetikzlibrary{trees}

\theoremstyle{ocrenum}
\newtheorem{solutionT}[dummy]{Solución}  % (Pedro: Corollary)
\newenvironment{solution}{\begin{cBox}\begin{solutionT}}{\end{solutionT}\end{cBox}}	


\newcommand{\tcolorboxsolucion}[2]{%
\begin{tcolorbox}[colback=green!5!white,colframe=green!75!black,title=#1] 
 #2
 %\tcblower  % pone una línea discontinua
\end{tcolorbox}
}% final definición comando

\newtcbox{\mybox}[1][green]{on line,
arc=0pt,outer arc=0pt,colback=#1!10!white,colframe=#1!50!black, boxsep=0pt,left=1pt,right=1pt,top=2pt,bottom=2pt, boxrule=0pt,bottomrule=1pt,toprule=1pt}



\mdfdefinestyle{exampledefault}{%
rightline=true,innerleftmargin=10,innerrightmargin=10,
frametitlerule=true,frametitlerulecolor=green,
frametitlebackgroundcolor=yellow,
frametitlerulewidth=2pt}





\newcommand{\betheorem}{\begin{theorem}}
\newcommand{\eetheorem}{\end{theorem}}
\newcommand{\bedefinition}{\begin{definition}}
\newcommand{\eedefinition}{\end{definition}}

\newcommand{\beremark}{\begin{remark}}
\newcommand{\eeremark}{\end{remark}}
\newcommand{\beexercise}{\begin{exercise}}
\newcommand{\eeexercise}{\end{exercise}}
\newcommand{\beexample}{\begin{example}}
\newcommand{\eeexample}{\end{example}}
\newcommand{\becorollary}{\begin{corollary}}
\newcommand{\eecorollary}{\end{corollary}}


\newcommand{\besolutionExe}{\begin{solutionExe}}
\newcommand{\eesolutionExe}{\end{solutionExe}}
\newcommand{\besolutionExa}{\begin{solutionExa}}
\newcommand{\eesolutionExa}{\end{solutionExa}}


%%%%%%%%


% Caja Salida Markdown
\newmdenv[skipabove=7pt,
skipbelow=7pt,
rightline=false,
leftline=true,
topline=false,
bottomline=false,
backgroundcolor=GreenYellow!10,
linecolor=GreenYellow!80,
innerleftmargin=5pt,
innerrightmargin=5pt,
innertopmargin=10pt,%5pt
innerbottommargin=5pt,
leftmargin=0cm,
rightmargin=0cm,
linewidth=4pt]{mBox}	

%% RMarkdown
\newenvironment{markdownsal}{\begin{mBox}}{\end{mBox}}	

\newcommand{\bmarkdownsal}{\begin{markdownsal}}
\newcommand{\emarkdownsal}{\end{markdownsal}}


\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{subfig} %new
%\usepackage{booktabs,dcolumn,rotating,thumbpdf,longtable}
\usepackage{dcolumn,rotating}  %new
\usepackage[graphicx]{realboxes} %new de: https://stackoverflow.com/questions/51633434/prevent-pagebreak-in-kableextra-landscape-table

%define el interlineado vertical
%\renewcommand{\baselinestretch}{1.5}

%define etiqueta para las Tablas o Cuadros
%\renewcommand\spanishtablename{Tabla}

%%\bibliographystyle{plain} %new no necesario


%%%%%%%%%%%% PARA USO CON biblatex
% \DefineBibliographyStrings{english}{%
%   backrefpage = {ver pag.\adddot},%
%   backrefpages = {ver pags.\adddot}%
% }

% \DefineBibliographyStrings{spanish}{%
%   backrefpage = {ver pag.\adddot},%
%   backrefpages = {ver pags.\adddot}%
% }
% 
% \DeclareFieldFormat{pagerefformat}{\mkbibparens{{\color{red}\mkbibemph{#1}}}}
% \renewbibmacro*{pageref}{%
%   \iflistundef{pageref}
%     {}
%     {\printtext[pagerefformat]{%
%        \ifnumgreater{\value{pageref}}{1}
%          {\bibstring{backrefpages}\ppspace}
%          {\bibstring{backrefpage}\ppspace}%
%        \printlist[pageref][-\value{listtotal}]{pageref}}}}
% 
%%% de kableExtra
\usepackage{booktabs}
\usepackage{longtable}
%\usepackage{array}
%\usepackage{multirow}
%\usepackage{wrapfig}
%\usepackage{float}
%\usepackage{colortbl}
%\usepackage{pdflscape}
%\usepackage{tabu}
%\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
%\usepackage{xcolor}

%%%%%%% fin: latex_preambulo.tex PLLC


\begin{document}

\bibliographystyle{flexbib}



\raggedbottom

\ifdefined\ifprincipal
\else
\setlength{\parindent}{1em}
\pagestyle{fancy}
\setcounter{tocdepth}{4}
\tableofcontents

\fi

\ifdefined\ifdoblecara
\fancyhead{}{}
\fancyhead[LE,RO]{\scriptsize\rightmark}
\fancyfoot[LO,RE]{\scriptsize\slshape \leftmark}
\fancyfoot[C]{}
\fancyfoot[LE,RO]{\footnotesize\thepage}
\else
\fancyhead{}{}
\fancyhead[RO]{\scriptsize\rightmark}
\fancyfoot[LO]{\scriptsize\slshape \leftmark}
\fancyfoot[C]{}
\fancyfoot[RO]{\footnotesize\thepage}
\fi

\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}

\hypertarget{preliminares}{%
\chapter{Preliminares}\label{preliminares}}

\hypertarget{datos-georreferenciados}{%
\section{Datos georreferenciados}\label{datos-georreferenciados}}

Todos los datos empleados en este trabajo son georreferenciados, lo que
significa que están asociados a ubicaciones geográficas específicas. Por
ello, resulta esencial introducir, aunque sea de forma general, los
tipos de datos más utilizados para trabajar con esta información, sus
características y las herramientas disponibles para manipularlos. Se
tratarán los datos vectoriales y los datos rasters, al ser los tipos de
datos fundamentales en este contexto, con características bien
diferenciadas entre ellos.

\hypertarget{datos-vectoriales}{%
\subsection{Datos Vectoriales}\label{datos-vectoriales}}

El modelo de datos vectoriales geográficos se basa en puntos ubicados
dentro de un sistema de referencia de coordenadas (CRS, por sus siglas
en inglés). Estos puntos pueden representar características
independientes o pueden estar conectados para formar geometrías más
complejas como líneas y polígonos.

\hypertarget{simple-features}{%
\subsubsection{Simple features}\label{simple-features}}

Las ``Simple features'' son un estándar abierto ampliamente usado para
la representación de datos vectoriales, desarrollado y respaldado por el
Open Geospatial Consortium (OGC, por sus siglas en inglés), una
organización sin ánimo de lucro dedicada a la creación de estándares
abiertos e interoperables a nivel global dentro del marco de los
sistemas geográficos de información (GIS, por sus siglas en ingés) y de
la World Wide Web.

El paquete sf proporciona clases para datos vectoriales geográficos y
una interfaz de línea de comandos consistente para importantes
bibliotecas de bajo nivel para geoprocesamiento (GDAL, PROJ, GEOS,
S2,\ldots).

Los objetos sf son fáciles de manipular ya que son dataframes o tibbles
con dos características fundamentales En primer lugar, contienen
metadatos geográficos adicionales: tipo de geometríca, dimensión,
``Bounding Box'' (límites o extensión geográfica) e información sobre el
Sistema de referencia de coordenadas. Y además, presentan una columna de
geometrías que tiene el nombre de ``geom''. Algunas ventajas del uso del
modelo de ``simple features'' en R son que en la mayoría de operaciones
los objeto sf se pueden tratar como data frames, los nombres de las
funciones son consistentes (todos empiezan por st\_), las funciones se
pueden combinar con el operador tubería y además funcionan bien con el
ecosistema de paquetes tidyverse.

El paquete sf de R soporta 18 tipos de geometrías para las simple
features, de las cuales las más utilizadas son: POINT, LINESTRING,
POLYGON, MULTIPOINT, MULTILINESTRING, MULTIPOLYGON and
GEOMETRYCOLLECTION.

\hypertarget{datos-raster}{%
\subsection{Datos Raster}\label{datos-raster}}

El modelo de datos raster representa el espacio con una cuadrícula de
celdas (también llamadas píxeles), que generalmente es regular, es
decir, con todas las celdas de igual tamaño. Aunque no se tratarán en el
presente trabajo, cabe mencionar que existen otros modelos de raster más
complejos en los que se usan cuadrículas irregulares (rotadas,
truncadas, rectilíneas o curvilíneas) y que pueden manipularse con el
paquete de R
(stars){[}\url{https://cran.r-project.org/web/packages/stars/index.html}{]}.
A cada una de estas celdas se le asocia uno (rasters de una sola capa) o
varios (rasters multicapa).

Los datos en formato raster constan de una cabecera y una matriz cuyos
elementos representan celdas equipespaciadas. En la cabecera del raster
se definen el Sistema de referencia de coordenadas, la extensión (o
límites espaciales del área cubierta por el ráster), la resolución y el
origen. El origen son las coordenadas de uno de los píxeles del ráster,
que sirve de referencia para los demás, siendo generalmente utilizado el
de la esquina inferior izquierda (aunque el paquete TERRA usado en este
trabajo usa por defecto el de la esquina superior izquierda). La
resolución se calcula como:

\[ resolution = \frac{x_{max}-x_{min}}{ncol},\frac{y_{max}-y_{min}}{nrow} \]

La representación en forma de matriz evita tener que almacenar
explícitamente las coordenadas de cada una de las cuatro esquinas de
cada píxel, debiendo almacenar solamente las coordenadas de un punto (el
origen). Esto, unido a las operaciones del álgebra de mapas hacen que el
procesamiento de datos raster sea mucho más eficiente que el de datos
vectoriales.

Se usará el paquete TERRA para tratar los datos en formato ráster. Este
paquete permite tratar el modelo de rásters regulares con una o varias
capas a través de la clase de objetos \texttt{SpatRaster}. Sin embargo,
existen otras alternativas, como el paquete
(stars){[}\url{https://cran.r-project.org/web/packages/stars/index.html}{]},
que además de ser más potente, permite trabajar con rásters no regulares
y ofrece una mejor integración con el paquete sf y el entorno tidyverse.

\hypertarget{sistemas-de-referencia-de-coordenadas}{%
\subsection{Sistemas de Referencia de
Coordenadas}\label{sistemas-de-referencia-de-coordenadas}}

Intrínseco a cualquier modelo de datos espaciales está el concepto de
Sistema de referencia de coordenadas (CRS), que establece cómo la
geometría de los datos se relaciona con la superficie terrestre. Es
decir, es el nexo de unión entre el modelo de datos y la realidad, por
lo que juega un papel fundamental. Los CRS pueden ser de dos tipos:
geográficos o proyectados.

\hypertarget{sistemas-de-coordenadas-geogruxe1ficas}{%
\subsubsection{Sistemas de Coordenadas
Geográficas}\label{sistemas-de-coordenadas-geogruxe1ficas}}

Los sistemas de coordenadas geográficas (GCS por sus siglas en inglés)
identifican cada punto de la superficie terrestre utilizando la longitud
y la latitud. La longitud es la distancia angular al Meridiano de
Greenwich medida en la dirección Este-Oeste. La longitud es la distancia
angular al Ecuador medida en la dirección Sur-Norte.

Cualquier sistema de coordenadas geográficas se compone de tres
elementos: el elipsoide, el geoide y el datum. El primero es el
elipsoide (o esfera) utilizado para representar de forma simplificada la
superficie terrestre, sobre el que se supone que se encuentran los datos
y el que permitirá realizar mediciones. El segundo, el geoide, es el
modelo matemático que representa la verdadera forma de la Tierra, que no
es suave sino que presenta ondulaciones debidas a las fluctuaciones del
campo gravitatorio a lo largo de la superficie terrestre, que además
cambian a una amplia escala temporal. Y el tercero, el datum, indica
cómo se alinean el elipsoide y el geoide, es decir, cómo el modelo
matemático se ajusta a la realidad. Este puede ser local o geocéntrico,
en función de si el elipsoide se ajusta al geoide en un punto concreto
de la superficie terrestre o de si el el centro del elipsoide el que se
alinea con el centro de la Tierra. Ejemplos de datums geocéntricos
usados en este trabajo son:

\begin{itemize}
\tightlist
\item
  European Terrestrial Reference System 1989 (ETRS89), usado ampliamente
  en la Europa Occidental.
\item
  World Geodetic System 1984 (WGS84), usado a nivel global.
\end{itemize}

\hypertarget{sistemas-de-coordenadas-proyectadas}{%
\subsubsection{Sistemas de Coordenadas
Proyectadas}\label{sistemas-de-coordenadas-proyectadas}}

Un Sistema de Coordenadas Proyectadas (PCS por sus siglas en inglés) es
un sistema de referencia que permite identificar localizaciones
terrestres y realizar mediciones en una superficie plana, es decir, en
un mapa. Estos sistemas de coordenadas se basan en las coordenadas
cartesianas, por lo que tienen un origen, un eje X y un eje Y y usan una
unidad lineal de medida (en este trabajo, metro). Pasar de una
superficie elíptica (GCR) a una superficie plana (PCS) requiere de
transformaciones matemáticas apropiadas y siempre induce deformaciones
en los datos.

Al proyectar la superficie terrestre en una superficie plana siempre se
modifican algunas propiedades de los objetos, como el área, la
dirección, la distancia o la forma. Un PCS solo puede conservar alguna
de estas propiedades, por lo que es habitual clasificar los PCS en
función de la propiedad que mantienen: las proyecciones de igual área
preservan el área, las azimutales preservan la dirección, las
equidistantes preservan la distancia y las conformales preservan la
forma local. La mayoría de las proyecciones también se pueden clasificar
en planas, cilíndricas o cónicas en función de cómo se realiza la
proyección.

Un caso particular y ampliamente usado de PCS cilíndrico son los
Universe Transverse Mercator (UTM), en el los que se proyecta el
elipsoide sobre un cilindro tangente a este por las líneas de longitud
(los meridianos). De esta forma, se divide el globo en 60 zonas de 6º de
longitud, para cada una de las cuales existe un PCS UTM correspondiente
que está asociado al meridiano central. Se trata de proyecciones
conformales, por lo que preservan ángulos y formas en pequeñas regiones,
pero distorsionan distancias y áreas.

A lo largo de este trabajo se utilizará ampliamente el Sistema de
coordenadas proyectadas UTM30N (es habitual especificar el hemisferio
para evitar confusión en los valores del eje Y, ya que miden distancia
al ecuador, de ahí la N de hemisferio norte).

\hypertarget{anuxe1lisis-exploratorio-de-datos}{%
\section{Análisis exploratorio de
datos}\label{anuxe1lisis-exploratorio-de-datos}}

El análisis exploratorio de datos (EDA, por sus siglas en inglés), es
una parte fundamental de todo proyecto de Machine Learning y en general
de cualquier proyecto en el que se deba trabajar con datos de cualquier
procedencia para extraer de ellos conclusiones. Antes del procesamiento
de los datos es siempre necesario explorar, entender y evaluar la
calidad de estos, pues como indica la expresión inglesa \emph{garbage
in, garbage out}, si trabajamos con datos pobres, no podemos esperar
obtener buenos resultados con ellos.

El EDA hace referencia al conjunto de técnicas estadísticas con las que
se pretende explorar, describir y resumir la naturaleza de los datos,
comprender las relaciones existentes entre las distintas variables
presentes, identificar posibles errores o revelar posibles valores
atípicos, todo esto con el objetivo de maximizar nuestra compresión
sobre el conjunto de datos.

\hypertarget{depuraciuxf3n-de-los-datos}{%
\subsection{Depuración de los datos}\label{depuraciuxf3n-de-los-datos}}

La depuración de los datos o \emph{data cleaning} es el proceso de
detectar y corregir o eliminar datos incorrectos, corruptos, con formato
incorrecto, duplicados o incompletos dentro de un conjunto de datos.
Puede considerarse una fase dentro del EDA (como se sugiere en R4DS,
Wickman) o una fase previa a este.

Puede entenderse que el \emph{data cleaning} es el proceso de pasar de
\emph{raw data} o datos en bruto a datos técnicamente correctos y
finalmente a datos consistentes.

Entendemos por datos técnicamente correcto cuando cada valor pertenece a
una variable y está almacenado en el tipo que que le corresponde en base
al conocimiento del dominio del problema. Para ello se debe reajustar el
tipo de cada variable al que le corresponda en base al conocimiento que
se tenga sobre esta, codificando los valores en las clases adecuadas si
fuese necesario.

Decimos que un conjunto de datos es consistente cuando es técnicamente
correcto y adecuado para el análisis estadístico. Se trata, por tanto,
de datos que han eliminado, corregido o imputado los valores faltantes,
los valores especiales, los valores atípicos y los errores.

\hypertarget{pca}{%
\subsection{PCA}\label{pca}}

\hypertarget{modelos}{%
\section{Modelos}\label{modelos}}

El problema que se aborda en este trabajo se engloba dentro de lo que se
conoce como aprendizaje supervisado, ya que para cada observación del
conjunto de entrenamiento se conoce el valor de la variable objetivo (en
este caso si ha habido incendio o no). Más concretamente, se trata de un
problema de clasificación binaria, ya que el objetivo es asignar cada
observación a una de las dos clases posibles (incendio o no incendio).
Existen numerosas técnicas de clasificación binaria supervisada, en este
trabajo se explorarán algunas de las de uso más común en problemas
similares.

\hypertarget{regresiuxf3n-loguxedstica-con-penalizaciuxf3n}{%
\subsection{Regresión logística (con
penalización)}\label{regresiuxf3n-loguxedstica-con-penalizaciuxf3n}}

La regresión logística es un caso particular de modelo lineal
generalizado basado en las siguientes hipótesis: - Hipótesis
distribucional. Dadas las variables explicativas,
\(\underline X_i \space \space \text{con} \space \space i = 1,2,...,n\),
se verifica que las variables \(Y|_{\underline X= \underline x_i}\) y su
distribución pertenece a la famila Bernouilli, es decir,

\[Y|_{\underline X= \underline x_i} \sim Be(\pi( \underline x_i))\]

\begin{itemize}
\tightlist
\item
  Hipótesis estructural. La esperanzara
  \(E(Y|_{\underline X= \underline x_i}) = \pi_i\) está relacionada con
  un predictor lineal (\(\eta_i = \beta^t z_i\)) a través de la función
  logit (con \(\underline z_i = \left(1,\underline x_i\right)\)) Es
  decir, dado que
  \[\eta_i = \underline \beta^t \underline z_i= \ln(\frac{\pi_i}{1-\pi_i}) \]
  O equivalentemente,
  \[\pi_i = \frac{\exp(\underline \beta^t \underline z_i)}{1 + \exp(\underline \beta^t \underline z_i)}\]
\end{itemize}

Bajo estas hipótesis, la función de log-verosimilitud dada una muestra
\(\{ (\underline x_i,y_i) \}_{i=1,...,n}\) es:

\[ l(\underline \beta) = 
\sum_{i=1}^n \left[ 
y_i\ln \left( \frac{\pi_i}{1-\pi_i} \right) + 
\ln \left( 1 - \pi_i\right) \right]\]

En la regresión logística clásica se estima el vector de parámetros
\(\underline \beta\) maximizando la función de log-verosimilud, o lo que
es equivalente, minimizando su opuesta. Por tanto, el problema de
optimización a resolver será
\[\min_{\underline \beta} -l(\underline \beta)\]

Sin embargo, con el objetivo de evitar el sobreajuste y construir
modelos con mayor capacidad de generalización existen variaciones de la
regresión logística que incluyen un término de penalización en la
función objetivo. Las dos variantes de uso más extendido son la
regresión \emph{ridge} y \emph{lasso}.

Sea \(\underline \beta = \left( \beta_0, \underline \beta_1 \right)\),
donde \(\underline \beta_1\) contiene los coeficientes de las
covariables. En la regresión \emph{ridge} el término de penalización es
de la forma \(\| \underline \beta_1 \|^2_2\) mientras que en la
regresión \emph{lasso} el penalización es de la forma
\(\| \underline \beta_1 \|_1\). Por tanto, el problema de optimización
será

\[\min_{\underline \beta} -l(\underline \beta)  + \lambda \sum \beta_i^2 \]
en el caso de la regresión logística \emph{ridge}, y
\[\min_{\underline \beta} -l(\underline \beta)  + \lambda \sum |\beta_i|\]
en el caso de la regresión logística \emph{lasso}.

El paquete glmnet implementa una combinación de ambos métodos (llamada
\emph{elastic net}), en la que se añade un parámetro de mezcla
\(\alpha \in \left[0,1\right]\) que combina ambos enfoques. El problema
de optimización resultante es:

\[\min_{\underline \beta} -l(\underline \beta)  + \lambda \left[(1-\alpha)\sum \beta_i^2 + \alpha \sum |\beta_i| \right]\]

\hypertarget{support-vector-machine}{%
\subsection{Support Vector Machine}\label{support-vector-machine}}

Las Máquinas de Vector Soporte (SVM por sus siglas en inglés) son una
familia de modelos principalmente usados en problemas de clasificación
binaria (si bien se pueden extender a problemas de clasificación
multiclase o regresión) que parten de la idea de encontrar el hiperplano
que mejor separa al conjunto de puntos.

\hypertarget{linear-svm}{%
\subsubsection{Linear SVM}\label{linear-svm}}

Dada una muestra \(\left\{(\underline x_i,y_i) \right\}_{i=1,...,n}\)
con \(\underline x_i \in \mathbb{R}^d\) y \(y_i \in \{-1,1\}\) para todo
\(i \in \{1,...,n\}\), el objetivo es encontrar al hiperplano de la
forma
\[h(x) = w_1x_1 +w_2x_2+...+w_dx_d +b = \underline w^t \underline x = 0 \]
que mejor separe a la muestra.

Se dice que la muestra muestra es linealmente separable si existe un
hiperplano, denominado hiperplano de separación, que cumple, para todo
\(i \in 1,...,n\):
\[\underline w^t \underline x_i + b \ge 0 \space \space \text{si} \space \space y_i=+1\]
\[\underline w^t \underline x_i + b \le 0 \space \space \text{si} \space \space y_i=-1\]

Dado un hiperplano de separación de una muestra linealmente separable,
se define el margen como la menor de las distancias del hiperplano a
cualquier elemento de la muestra. Se denotará por \(\tau\).

Dado un punto \(\underline x_i\) y un hiperplano
\(h(x) = w_1x_1 +w_2x_2+...+w_dx_d +b = \underline w^t \underline x = 0\),
la distancia entre ambos viene dada por:
\[d(h,\underline x_i) = \frac{|h(\underline x_i)|}{\|w\|} = \frac{y_i(\underline w^t \underline x_i+b)}{\|w\|}\]
Donde \(\|\cdot\|\) hace referencia a la norma euclídea.

Dada una muestra linealmente separable
\(\left\{(\underline x_i,y_i) \right\}_{i=1,...,n}\) con
\(\underline x_i \in \mathbb{R}^d\) y \(y_i \in \{-1,1\}\) y un
hiperplano de separación \(h(x) = \underline w^t \underline x = 0\) con
margen \(\tau\), se verifica que
\[\frac{y_i(\underline w^t \underline x_i+b)}{\|w\|} \ge \tau \;\;\; \forall i\in \{1,...,n\}\]
O equivalentemente,
\[y_i(\underline w^t \underline x_i+b) \ge \tau\|w\| \;\;\; \forall i\in \{1,...,n\}\]
Y, además, es posible reescribir el mismo hiperplano \(h\) de forma que
\(\tau\|w\| = 1\).

De está ultima expresión se deduce que maximizar el margen \(\tau\) es
equivalente a minimizar la norma euclídea de \(w\). Por tanto, para
encontrar el hiperplano de separación óptimo para una muestra en las
condiciones de la proposición anterior basta resolver el problema de
optimización siguiente:

\begin{equation}
\begin{aligned}
\min_{w,b} \quad & \frac{1}{2}w^{t}w\\
\textrm{s.t.} \quad & \underline w^t \underline x_i+b \ge 1, \quad & \forall i\in \{1,...,n\} \\
  & w \in \mathbb{R}^d, \space b \in \mathbb{R} \\ 
\end{aligned}
\end{equation}

En general, las muestras no son separables, por lo que es necesario
permitir que pueda haber casos mal clasificados y penalizarlos
proporcionalmente a la distancia a la que se encuentren del subespacio
correcto (holgura). Para ello, se introducen en la formulación del
modelo las variables artificiales \(\xi_i,\quad i=1,...,n\). Se habla
entonces de hiperplano de separación \emph{soft margin}. De esta forma,
se llega al problema de optimización siguiente:

\begin{equation}
\begin{aligned}
\min_{w,b,\xi} \quad & \frac{1}{2}w^{t}w+C\sum_{i=1}^{n}{\xi_{i}}\\
\textrm{s.t.} \quad & \underline w^t \underline x_i+b \ge 1, \quad & \forall i\in \{1,...,n\}\\
  &\xi\geq0,   \quad & \forall i\in \{1,...,n\} \\
  & w \in \mathbb{R}^d, \space b \in \mathbb{R} \\
\end{aligned}
\end{equation}

\hypertarget{random-forest}{%
\subsection{Random Forest}\label{random-forest}}

\hypertarget{redes-neuronales}{%
\subsection{Redes Neuronales}\label{redes-neuronales}}

\hypertarget{validaciuxf3n-del-ajuste}{%
\section{Validación del ajuste}\label{validaciuxf3n-del-ajuste}}

Partición entrenamiento/ validación / test

\hypertarget{evaluaciuxf3n-modelos}{%
\section{Evaluación modelos}\label{evaluaciuxf3n-modelos}}

Una vez construido un modelo predictivo es necesario conocer el
rendimiento de este sobre nuevos datos, con el objetivo de estimar su
capacidad de generalización. Esto es fundamental de cara a determinar si
el modelo es adecuado para el propósito previsto o si necesita ajustes o
mejoras. Además, la evaluación del rendimiento permite comparar entre
diferentes modelos y seleccionar el que mejor se adapte a las
necesidades específicas del problema en cuestión. Para ello, se recurre
a distintas métricas, en función de las características propias de cada
problema.

\hypertarget{clasificaciuxf3n-binaria}{%
\subsection{Clasificación binaria}\label{clasificaciuxf3n-binaria}}

En el presente trabajo el problema que se aborda es un problema de
clasificación binaria, pues tenemos solo dos clases que son la clase
positiva y la clase negativa. A la hora de clasificar una nueva
instancia pueden darse 4 situaciones:

\begin{itemize}
\item
  Que se clasifique como positiva siendo realmente positiva, en cuyo
  caso se dirá que forma parte de las \emph{True Positives (TP)}
\item
  Que se clasifique como negativa siendo realmente negativa, en cuyo
  caso se dirá que forma parte de las \emph{True Negatives (TN)}
\item
  Que se clasifique como positiva siendo realmente negativa, en cuyo
  caso se dirá que forma parte de las \emph{False Positives (FP)}
\item
  Que se clasifique como negativa siendo realmente positiva, en cuyo
  caso se dirá que forma parte de las \emph{False Negatives (FN)}
\end{itemize}

Se definen las siguientes métricas de rendimiento de un modelo de
clasificación binaria:

\textbf{Tasa de acierto o exactitud}. Mide la proporción de casos que
han sido correctamente clasificados.
\[Exactitud = \frac{TP + TN}{TP + FP + TN + FN}\]

\textbf{Precisión}. Mide la proporción de casos clasificados como
positivos que realmente lo son. \[ Precisión = \frac{TP}{TP + FP}\]

\textbf{Especificidad}. Mide la proporción de casos negativos que han
sido correctamente clasificados por el modelo.
\[ Especificidad = \frac{TN}{TN + FP}\]

\textbf{Sensibilidad o recall}. Mide la proporción de casos positivos
que han sido correctamente clasificados por el modelo.
\[ Recall = \frac{TP}{TP + FN}\]

\textbf{AUC-ROC}. Mide el área bajo la curva ROC (\emph{Receiver
Operating Characteristic} o Característica Operativa del Receptor en
castellano). Esta curva es una representación gráfica del rendimiento de
un modelo de clasificación binaria para todos los umbrales de
clasificación.

\hypertarget{herramientas}{%
\section{Herramientas}\label{herramientas}}

Toda la parte práctica del presente trabajo se ha llevado a cabo
empleado el lenguaje de programación R a través del entorno de
desarrollo integrado (IDE) que ofrece RStudio. R es un lenguaje y
entorno de programación de código abierto desarrollado dentro del
proyecto GNU y orientado a la computación estadística. R puede extender
sus funcionalidades fácilmente a través de la gran cantidad de paquetes
disponibles dentro del repositorio de paquetes de CRAN (The
Comprehensive R Archive Network), siendo este uno de sus puntos fuertes,
dada la gran comunidad de usuarios y desarrolladores con las que cuenta
este lenguaje.

Los paquetes que se han utilizado han sido:

\begin{itemize}
\item
  tidyverse:

  • ggplot2, para la visualización. • dplyr, para la manipulación. •
  tidyr, para la ordenación. • readr, para la importación. • purrr, para
  la programación funcional
\item
  tidymodels
\item
  sf
\item
  terra
\item
  nasapower: obtención de información climática satelital
\item
  mapSpain:
\end{itemize}

\ldots{} (podemos seguir hasta el infinito)

\bibliography{bib/library.bib,bib/paquetes.bib}


%


\end{document}
