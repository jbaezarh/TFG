---
output:
  pdf_document:
    keep_tex: yes
    number_sections: yes
    citation_package: natbib  # comentado usa: pandoc-citeproc
    template: latex/templateMemoriaTFE.tex
    pandoc_args: ["--metadata-file=cabecera_capitulos.yaml"]
  html_document: default
#bibliography: bib/library.bib # descomentar si: editor visual RStudio  
---

<!-- escribir 2 para capítulo 3 -->
<!-- \setcounter{chapter}{2} --> 
<!-- \pagenumbering{arabic} -->

`r xfun::file_string('cabecera_capitulos.tex')`

```{r include=FALSE}
source("cabecera_chunk_inicio.R")
```


# Apéndice: Código

## Generación de la muestra
```{r eval=FALSE}
# Librerías ---------------------------------------------------------------
# Se cargan las librerías que se usarán en esta sección

library(terra) # Raster data
library(sf) # Vector data
library(mapSpain) # Polígonos de las regiones de España
library(tidyverse) # Manipulación de datos



# CRS de referencia -------------------------------------------------------
# Será el CRS que se use en todo el proyecto

pend <- rast("data_raw/topograficas/pendiente.tif")
crs_reference = crs(pend)
rm(pend) # Se elimina de la memoria para liberar espacio


# Polígono de Andalucía ---------------------------------------------------
Andalucia <- esp_get_ccaa(ccaa = "Andalucía") # Se obtiene el polígono de la comunidad autónoma de Andalucía
andalucia_proj <- st_transform(Andalucia,crs_reference) # Se transforma al sistema de referencia usado en el proyecto

# area_monte es el área donde se generarán las muestras negativas.

# Dado que no hay un mapa que indique claramente cuales son las zonas que se consideran "monte" en Andalucía y dado que los polígonos de incendios también cubren zonas agrícolas y urbanas (aunque menores en número que las zonas forestales), se considerará "monte" toda Andalucía, sin distinción. El sentido de esta variable es, precisamente, que pueda modificarse en futuros estudios
area_monte <- andalucia_proj

# Generación de la muestra ------------------------------------------------

# Generación de la muestra estratificando por mes de forma que la proporción de observaciones positivas y negativas por mes (en todo el periodo) sea la misma

##  Tamaño muestral -----------------------------------------------------
# Se dispone de 1089 incencios correctamente registrados entre 2002 y 2022

n_in=10 # Número de puntos a muestrear dentro de cada poligono
n_out=1089*10 # Número de muestras negativas

##  Generación aleatoria de fechas para las muestras negativas ----------

# Primero se leen todos los datos de todos los archivos de incendios y se almacenan en la variable incendios
incendios = NULL

for (year in 2002:2022) {
  incendios = rbind(incendios, 
                    st_read(paste0("./data_raw/incendios_2000-2022/incendios_",year,".shp")) %>% 
                      select("FECHA_INIC" = matches("(?i)^FECHA_INIC$|^fecha_inic.$"))) 
}

# Se cuenta el número de incendios con fecha de inicio correcta en cada mes
incendios_mes = incendios %>% 
  mutate(FECHA_INIC = ymd(FECHA_INIC),.keep="unused") %>% 
  filter(!is.na(FECHA_INIC)) %>% 
  filter(year(FECHA_INIC)<=2022,year(FECHA_INIC)>=2002) %>% 
  st_drop_geometry() %>% 
  mutate(MES = month(month(FECHA_INIC))) %>% 
  count(MES) 

# Fechas posibles para las muestras negativas
possible_dates = tibble (date = seq(as.Date('2002/01/01'), as.Date('2022/12/31'), by="day")) %>% 
  mutate(MES = month(date)) %>% 
  left_join(incendios_mes,
            join_by(MES)) 

set.seed(12345) # Se fija la semilla para que sea reproducible

# Se generan fechas aleatorias para las muestras negativas entre 2002 y 2022 siguiendo con una distribución de probabilidad proporcional a la cantidad de incendios observados en cada mes
dates = sample(possible_dates$date, 
               n_out,replace = T,
               prob = possible_dates$n) 

rm(incendios, possible_dates) # Se borran para liberar memoria

##  Selección de localizaciones aleatorias ------------------------------
# Para la selección de la muestra se seguirá el siguiente procedimiento:
# 1. Para las muestra positivas: Se tomarán n_in puntos aleatorios dentro de cada polígono de incendio y se le asociará a cada uno de ellos la fecha de inicio del incendio.
# 2. Para la muestras negativas: Se le asociará una localización aleatoria dentro de area_monte a cada una de las fechas aleatorias generadas dentro del periodo de estudio (dates). Se tendrá en cuenta que no pueden haber muestras negativas a menos de 15km de una zona en la que haya habido un incendio en una franja de 6 días alrededor de la fecha de la observación (3 días antes a 3 días después).

points_in = NULL  # Almacena las muestras positvas
points_out = NULL # Almacena las muestras negativas

for (year in 2002:2022) {
  
  cat("YEAR ", year," : -------------------------------------\n")
  cat("  Generando muestras positivas...\n")
  incendios <- st_read(paste0("./data_raw/incendios_2000-2022/incendios_",year,".shp"),quiet=T) |> 
    st_transform(crs = crs_reference) |> 
    rename_with(.fn=tolower) |> 
    mutate(fecha_inic=ymd(fecha_inic),geometry,.keep="none")
  
  
  ## Generación de puntos positivos
  
  for (i in 1:nrow(incendios)) {
    point_in_sfc <- st_sample(incendios[i,],size=n_in) # Se generan n_i puntos dentro de cada incendio
    point_in_attr <- data.frame(fire = rep(1,n_in),date = rep(incendios[i,]$fecha_inic,n_in))
    point_in <- st_sf(point_in_attr,geometry= point_in_sfc)
    
    if (is.null(points_in)) {
      points_in <- point_in 
    } else {
      points_in <- points_in |> 
        add_row(point_in) 
    }
  }
  
  ## Generación de puntos negativos
  
  cat("  Generando muestras negativas...\n")
  # ---> Nota: los puntos se generan en area_monte
  
  dates_year <- dates[year(dates) == year]
  locations = NULL
  
  for (day in dates_year) {
    incendios_day = filter(incendios,fecha_inic>=day-3 & fecha_inic<=day+3)
    if (nrow(incendios_day)==0){ # Si no ha habido incendios en una franja de 6 días en Andalucía
      if (is.null(locations)) {
        locations = st_sample(area_monte,size=1)
      } else {
        locations = c(locations, st_sample(area_monte,size=1))
      }
    } else { # Si ha habido algún incendio en una franja de 6 días en Andalucía (3 antes o 3 después)
      repeat {
        possible_location = st_sample(area_monte,size=1)
        if (!st_is_within_distance(possible_location,st_union(incendios_day), dist = 15000, sparse = FALSE)) {
          possible_location = st_sample(area_monte,size=1)
          if (is.null(locations)) {
            locations = possible_location
            break
          } else {
            locations = c(locations, possible_location)
            break
          }
        }
      }
    }
  }
  
  
  points_out_attr <- data.frame(fire = rep(0,length(dates_year)),date = dates_year)
  
  if (is.null(points_out)) {
    points_out <- st_sf(points_out_attr,geometry= locations)
  } else {
    points_out <- points_out |> 
      add_row(st_sf(points_out_attr,geometry= locations)) 
  }
  
}


sample <- rbind(points_in,points_out) # La muestra generada


# Comprobación y corrección -----------------------------------------------
summary(sample) # Hay una fecha de un incendio errónea
max(sample$date,na.rm=T) # "2033-08-15"

# Se eliminan las observaciones con fecha de incendio errónea que se han detectado
sample <- sample[-which(sample$date==max(sample$date,na.rm=T)),]
summary(sample) # Corregido

# Almacenamiento de resultados --------------------------------------------
save(sample,file=paste0("salidas_intermedias/sample_strat_",Sys.Date(),".RData"))
```

## Asignación de variables a localizaciones

A continuación se define la función `asignar_variables` que dada una muestra de puntos en Andalucía con fechas comprendidas entre 2002 y 2022 le asocia a cada observación todos los valores de las variables consideradas en el estudio. Esta función se usará varias veces a lo largo del trabajo.

```{r eval=FALSE}
# Librerías ---------------------------------------------------------------
# Se cargan las librerías que se usarán en esta sección

library(nasapower) # Para obtener la información meteorológica
library(raster, include.only = c("rasterFromXYZ"))  # Función para construir rasters a partir de data.frames
library(tidyverse) 
library(sf)
library(terra)
library(mapSpain)


asignar_variables = function(sample) {
  
  # Argumentos:
  # * sample: objeto sf con una columna de geometrías de tipo POINT (dentro de los límites de Andalucía) y fechas comprendidas entre 01/01/2002 y 31/12/2022 

  
  crs_reference = st_crs(sample) # Se usa el sistema de referencia de coordenadas de la muestra
  and = esp_get_ccaa(ccaa = "Andalucía") %>% st_transform(st_crs(datos)) # Polígono de Andalucía
  
  # Variables meteorológicas ------------------------------------------------
  cat("Asignando variables meteorológicas...\n")
  
  # Tranformamos los datos a WGS84
  andalucia_WGS84 <- st_transform(and,crs="WGS84")
  
  dataset = NULL # Variable en la que se almacenará el conjunto completo
  
  # Se trabaja anualmente pues la API de NASA POWER solo admite consultas de hasta 366 días

  for (year in sort(unique(year(sample$date)))) {
    
    cat("YEAR ", year," : -------------------------------------\n")
    
    # Los puntos de cada año
    points = filter(sample,year(date)==year)  
    points_WGS84 <- st_transform(points,crs="WGS84")
    
    # Consulta a la api para obtener todo los valores del año
    daily_single_ag <- get_power(
      community = "ag",
      lonlat = c(-8,35.5,-1.5,39),  # Límites de Andalucía
      pars = c("T2M","GWETTOP", "RH2M","WD10M","WS10M","PRECTOTCORR"),
      dates = paste0(year,c("-01-01","-12-31")),
      temporal_api = "daily")
    
    # Identificador
    daily_single_ag$clim_id <- 1:nrow(daily_single_ag)
    points$clim_id = NA # Inicializo el identificador
    
    for (day in unique(points$date)) {
      
      points_day = points$date==day
      
      # Seleccionar un día
      clim_day  <- filter(daily_single_ag,YYYYMMDD==day) |> 
        dplyr::select(x = LON,y = LAT,clim_id= clim_id)
      
      id_rast_day = rast(rasterFromXYZ(clim_day,crs="WGS84")) # Se crea el raster con los identificadores
      
      points[points_day,]$clim_id <- terra::extract(id_rast_day,points_WGS84[points_day,])$clim_id # Se asocia a cada registro de la muestra el identificador correspondiente
    }
    
    # Haciendo uso del identificador se asocian todas las variables meteorológicas correspondientes a cada registro
    points <- points |> 
      left_join(select(daily_single_ag, -c(LAT,LON,DOY,YYYYMMDD)),
                by=join_by(clim_id)) |> 
      select(-clim_id) 
    
    dataset = rbind(dataset,points)
  }
  
  rm(points,points_WGS84,daily_single_ag,clim_day,id_rast_day,points_day,day,year,andalucia_WGS84)
  
  
  # Variables topográficas --------------------------------------------------
  cat("Asignando variables topográficas...\n")
  elev <- rast("data_raw/topograficas/elevacion.tif")
  pend <- rast("data_raw/topograficas/pendiente.tif")
  orient <- rast("data_raw/topograficas/orientacion.tif")
  curv <- rast("data_raw/topograficas/curvatura.tif")
  
  # Es necesario pasarlas a numeric para poder trabajar con ellas y extraer los valores
  pend <- as.numeric(pend)
  orient <- as.numeric(orient)
  curv <- as.numeric(curv)
  
  # Se extraen los valores de cada una de las capas
  var_topograficas <- list(elevacion = elev,pendiente = pend,orientacion = orient,curvatura = curv)
  
  points_topograficas <- sapply(var_topograficas,function(x) terra::extract(x,dataset))[2,] |> 
    as_tibble()
  
  dataset <- cbind(dataset,points_topograficas)
  
  rm(elev,pend,orient,curv,var_topograficas,points_topograficas)
  
  
  # Variables antropológicas ------------------------------------------------
  cat("Asignando variables antropológicas...\n")
  
  ## Para optimizar el cálculo evitando que se repitan cálculos si hay puntos repetidos:!!
  dataset_geoms <- dataset %>% 
    group_by(geometry) %>% 
    group_keys() %>% 
    st_sf(crs = st_crs(dataset)) 
  
  ### Carreteras: ----
  carreteras <- read_sf("data_raw/antropologicas/RedCarreteras/09_14_RedCarreteras.shp") |> 
    st_union()
  
  dataset_geoms$dist_carretera <- st_distance(dataset_geoms,carreteras) |> 
    as.numeric()      # metres

  rm(carreteras)
  
  ### Poblaciones: ----
  poblaciones <- read_sf("data_raw/antropologicas/Poblaciones/07_01_Poblaciones.shp") |> 
    st_union()
  
  dataset_geoms$dist_poblacion <- st_distance(dataset_geoms,poblaciones) |> 
    as.numeric()    # metres
  
  rm(poblaciones)
  
  ### Linea Eléctrica: ----
  linea_electrica <- read_sf("data_raw/antropologicas/LineaElectrica/10_14_LineaElectrica.shp") |> 
    st_union()
  
  dataset_geoms$dist_electr <- st_distance(dataset_geoms,linea_electrica) |> 
    as.numeric() # metres
  
  rm(linea_electrica)
  
  ### Ferrocarril: ----
  ferrocarril <- read_sf("data_raw/antropologicas/Ferrocarril/09_21_Ferrocarril.shp") |> 
    st_union()
  dataset_geoms$dist_ferrocarril <- st_distance(dataset_geoms,ferrocarril) |> 
    as.numeric()
  
  rm(ferrocarril)
  
  ### Camino / Via: ----
  camino <- read_sf("data_raw/antropologicas/Camino/09_19_Camino.shp") 
  viapec <- read_sf("data_raw/antropologicas/Camino/09_22_ViasPecuarias.shp") 
  
  camino_viapec <- c(st_geometry(camino),st_geometry(viapec))
  rm(camino,viapec)
  
  camino_viapec <- st_union(camino_viapec)
  
  dataset_geoms$dist_camino <- st_distance(dataset_geoms,camino_viapec) |> 
    as.numeric()
  
  rm(camino_viapec)
  
  ### Sendero / Vía Verde / CarrilBici: ----
  viaverde <- read_sf("data_raw/antropologicas/Sendero_ViaVerde/09_24_ViaVerde.shp") 
  sendero <- read_sf("data_raw/antropologicas/sendero_ViaVerde/09_20_Sendero.shp") 
  carrilbic <- read_sf("data_raw/antropologicas/sendero_ViaVerde/09_23_CarrilBici.shp")
  
  sendero_viaverde_carrilbici <- c(st_geometry(viaverde),st_geometry(sendero),st_geometry(carrilbic)) |> 
    st_union()
  
  dataset_geoms$dist_sendero <- st_distance(dataset_geoms,sendero_viaverde_carrilbici) |> 
    as.numeric()
  
  rm(sendero,sendero_viaverde_carrilbici,viaverde,carrilbic)
  
  ### ENP: ----
  enp1 <- read_sf("data_raw/antropologicas/ENP/11_07_Enp_FiguraProteccion.shp" )
  enp2 <- read_sf("data_raw/antropologicas/ENP/11_07_Enp_RegimenProteccion.shp")
  
  enp <- c(st_geometry(enp1),st_geometry(enp2)) |>  st_union()
  enp_sf <- st_sf(enp)
  
  # Se rasteriza para aumentar la eficiencia computacional
  enp_rast <- rasterize(enp_sf,
                        rast("data_raw/topograficas/pendiente.tif"), # Modelo
                        background = 0)
  dataset_geoms$enp= terra::extract(enp_rast,dataset_geoms)[,2]
  
  rm(enp,enp1,enp2,enp_sf,enp_rast)
  
  ### Uso Suelo: ----
  # Inicialmente se ha rasterizado para aumentar la eficiencia computacional
  # UsoSuelo <- read_sf("data_raw/antropologicas/UsoSuelo/06_01_UsoSuelo.shp")
  # UsoSuelo_rast <- rasterize(UsoSuelo,
  #                            rast("data_raw/topograficas/pendiente.tif"), # Modelo
  #                            field="cod_uso")
  
  UsoSuelo_rast <- rast("data_cleaning/uso_suelo_rast.tiff")
  
  dataset_geoms$uso_suelo = terra::extract(UsoSuelo_rast,dataset_geoms)[,2]
  
  # Hidrográficas -----------------------------------------------------------
  cat("Asignando variables hidrográficas...\n")
  
  ### Distancia a ríos: ----
  rios <- read_sf("data_raw/hidrograficas/Rios_Espana.shp") |> 
    st_transform(st_crs(dataset)) |> 
    st_crop(xmin = 100394.4, # Esto se hace solo para no tener que considerar todo el file y que sea más eficiente computacionalmente
            ymin = 3976888.6,
            xmax = 690000.8,
            ymax = 4350000.0) |> 
    st_union()
  
  dataset_geoms$dist_rios <- st_distance(dataset_geoms,rios) |> 
    as.numeric() # metres
  
  rm(rios)
  
  ##  Se vuelven a desagrupar los registros y se le asigna a cada registro los valores correspondientes calculados!!
  dataset <- dataset %>% 
    st_join(dataset_geoms,left = TRUE) # Es un left join espacial
  
  # Demográficas -----------------------------------------------------------
  cat("Asignando variables demográficas...\n")
  
  ### Población y densidad de población: ----
  
  poblacion <- read_csv2("data_raw/antropologicas/Población/poblacion_municipios.txt",
                         locale=locale(decimal_mark = ","),
                         col_select = 1:5,col_types = "ccifn") |> 
    mutate(Valor=as.integer(round(Valor))) # Por algún motivo aparecen decimales
  
  
  area_municipios <- read_csv2("data_raw/antropologicas/Población/extension_municipal.txt",
                               locale=locale(decimal_mark = ","),
                               col_select = 1:6, col_types = "fffffn")

  area_municipios <- area_municipios %>% 
    filter(!is.na(CODIGO_INE3)) %>% 
    select(CODIGO_INE3,Valor) %>% 
    rename("Area" = "Valor")
  
  # Se calcula la densidad de población anual como el cociente del número de habitantes entre la extensión del municipio
  dens_poblacion <- poblacion %>% 
    select(-Medida) %>% 
    rename("Poblacion" = "Valor",
           "Municipio" = "Lugar de residencia") %>% 
    left_join(area_municipios,
              join_by("CODIGO_INE3")) %>% 
    mutate(dens_poblacion = Poblacion/Area) %>% 
    select(-Area)
  
  municipios <- esp_get_munic(epsg = 4258,region = "Andalucía")
  
  municipios <- municipios |> 
    st_transform(crs_reference)
  
  # Se asocia cada observacion su código de municipio correspondiente 
  
  num_mun = st_intersects(dataset,municipios) 
  
  # Se eliminan las observaciones que no están en ningún municipio 
  if (any(sapply(num_mun,function(x) length(x) == 0))) {
    cat("Eliminamos las observaciones:\n",which(sapply(num_mun,function(x) length(x) == 0)))
    dataset = dataset[-which(sapply(num_mun,function(x) length(x) == 0)),]
  }
  
  dataset$cod_municipio <- municipios[unlist(st_intersects(dataset,municipios)),]$LAU_CODE
  
  dataset <- dataset |> 
    left_join(dens_poblacion,
              join_by(cod_municipio==CODIGO_INE3,YEAR==Anual)) |> 
    rename("municipio" = "Municipio",
           "poblacion" = "Poblacion")
  
  # Vegetación --------------------------------------------------------------
  cat("Asignando variables de vegetación...\n")
  
  ### NDVI ----
  dataset$NDVI = NA
  
  for (YEAR in 2002:2022) {
    for (MONTH in 1:12) {
      MM = str_pad(MONTH,2,"left",pad = "0")
      YY = substr(as.character(YEAR),3,4)
      # if (as.numeric(YY)<=01) {
      #   ruta <- paste0("data_raw/vegetacion/",YEAR,"NOAAVHMEDMNDVI/InfGeografica/InfRaster/TIF/NOAAVH_",YY,MM,"01_Andaluz_MEDMndvi.tif")
      # } else 
      if (as.numeric(YY)<=06) {
        ruta <- paste0("data_raw/vegetacion/",YEAR,"TERMODMEDMNDVI/InfGeografica/InfRaster/TIFF/TERMOD_",YY,MM,"01_h17v05_medmndvi.tif")
      } else if (as.numeric(YY)<=11) {
        ruta <- paste0("data_raw/vegetacion/",YEAR,"TERMODMEDMNDVI/InfGeografica/InfRaster/TIF/TERMOD_",YY,MM,"01_h17v05_medmndvi.tif")
      } else if (as.numeric(YY)<=21) {
        ruta <- paste0("data_raw/vegetacion/",YEAR,"TERMODMEDMNDVI/InfGeografica/InfRaster/TIFF/termod_",YY,MM,"01_h17v05_medmndvi.tif")
      }else {
        ruta <- paste0("data_raw/vegetacion/",YEAR,"TERMODMEDMNDVI/InfGeografica/InfRaster/COG/termod_",YY,MM,"01_h17v05_medmndvi_COG.tif")
      }
      
      if (file.exists(ruta)) {
        cat(YEAR,MONTH,"\n")
        # Observaciones en ese mes y año
        isMY = dataset$YEAR==YEAR & dataset$MM==MONTH
        if (any(isMY)) {
          NDVI_rast = as.numeric(rast(ruta))
          if (MONTH==4 & YEAR==2011){
            # Ese archivo viene defectuoso y se le asigna el CRS de los otros archivos del mismo año (todos los demás del año tienen el mismo)
            crs(NDVI_rast) = "PROJCRS[\"WGS 84 / UTM zone 30N\",\n    BASEGEOGCRS[\"WGS 84\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 30N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",-3,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 6°W and 0°W, northern hemisphere between equator and 84°N, onshore and offshore. Algeria. Burkina Faso. Côte' Ivoire (Ivory Coast). Faroe Islands - offshore. France. Ghana. Gibraltar. Ireland - offshore Irish Sea. Mali. Mauritania. Morocco. Spain. United Kingdom (UK).\"],\n        BBOX[0,-6,84,0]],\n    ID[\"EPSG\",32630]]"
          } 
          
          dataset[isMY,]$NDVI = terra::extract(NDVI_rast,dataset[isMY,])[,2]
        }
      } else
        cat("No existe: ",YEAR,"-",MONTH,"\n")
    } 
  }
  
  
  # Factores -------------------------------------------------------------
  # Codificación de las variables categóricas como factores:
  
  dataset <- dataset |> 
    mutate(enp = as.factor(enp),
           orientacion = cut(orientacion,
                             breaks = c(-Inf,-1,22.5,67.5,112.5,157.5,202.5,247.5,292.5,337.5,360),
                             labels = c("Plano","N","NE","E","SE","S","SW","W","NW","N")),
           WD10M = cut(WD10M,
                       breaks = c(0,22.5,67.5,112.5,157.5,202.5,247.5,292.5,337.5,360),
                       labels = c("N","NE","E","SE","S","SW","W","NW","N")),
           uso_suelo = uso_suelo |> as.character() |> str_sub(0,2) |> as.factor()
           ) %>% 
    select(-c(YEAR,MM,DD))
  
  return(dataset)
}
```

Se usa la función definida para asignar las variables explicativas a la muestra generada:
```{r eval=FALSE}
# Se carga la muestra generada en el paso anterior:
load("salidas_intermedias/sample_strat_2024-04-26.RData")

# Se eliminan las observaciones que no tienen fecha pues se pueden usar para el estudio
sample <- na.omit(sample)

# Se aplica la función a la muestra 
dataset <- asignar_variables(sample)

# Se almacenan los resultados
save(dataset,file = paste0("salidas_intermedias/dataset_strat_completo",Sys.Date(),".RData"))
```

## Depuración de la muestra
```{r eval=FALSE}
# Librerías ---------------------------------------------------------------
# Se cargan las librerías que se usarán en esta sección
library(tidyverse) # Manipulación de datos 
library(sf) # Vector data
library(terra) # Raster data
library(mapSpain) # Polígonos de regiones de España
library(magrittr) # Operador %<>% 

# Carga de los datos ------------------------------------------------------
# Se carga la muestra con todas las variables construida anteriormente
load("salidas_intermedias/dataset_strat_completo2024-04-26.RData")


summary(datos)

datos <- datos |> 
  mutate(fire = as.factor(fire))

datos1 = datos %>% drop_na()

```

## Análisis exploratorio
```{r eval=FALSE}

```

## Modelos
```{r eval=FALSE}

```

## Casos de interés
```{r eval=FALSE}

```

