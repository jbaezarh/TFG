step_date(date,features = c("dow", "month")) %>%
# step_holiday(date) %>%
step_rm(date, cod_municipio, municipio)
# 3º Ensamblar todo con workflow
rf_workflow1 <-
workflow() %>%
add_model(rf_mod1) %>%
add_recipe(rf_recipe)
# 4º Train and tune
set.seed(345)
rf_res1 <-
rf_workflow %>%
tune_grid(val_set,
grid = expand_grid(min_n = seq(1000,2500,100)),
control = control_grid(save_pred = TRUE),
metrics = metric_set(accuracy,roc_auc,recall,spec))
rf_res1 <-
rf_workflow1 %>%
tune_grid(val_set,
grid = expand_grid(min_n = seq(1000,2500,100)),
control = control_grid(save_pred = TRUE),
metrics = metric_set(accuracy,roc_auc,recall,spec))
rf_tuning1 <- rf_res1 |>
collect_metrics() |>
group_by(.metric)|>
summarise(max = max(mean),min=min(mean))
rf_tuning1
rf_plot1 <-
rf_res1 %>%
collect_metrics() %>%
mutate(.metric = ifelse(.metric == "recall","spec",
ifelse(.metric == "spec","recall",
.metric))) %>%
ggplot(aes(x = min_n, y = mean,col=.metric)) +
geom_point() +
geom_line() +
ylab("") +
theme_minimal()+
labs(title = "Etapa 1\nFijado mtry = 4, se ajusta min_n")
# Mejor modelo
rf_best1 <-
rf_res1 %>%
select_best(metric = "spec")
rf_best1
rf_metrics1 <- rf_res1 |>
collect_predictions(parameters = rf_best1) |>
get_metrics()
rf_metrics1
# 1º Se construye el modelo
rf_mod2 <-
rand_forest(mtry = tune(), min_n = rf_best1$min_n, trees = 1000) %>%
set_engine("ranger", num.threads = cores) %>%
set_mode("classification")
# 3º Ensamblar todo con workflow
rf_workflow2 <-
workflow() %>%
add_model(rf_mod2) %>%
add_recipe(rf_recipe)
# 4º Train and tune
set.seed(345)
rf_res2 <-
rf_workflow2 %>%
tune_grid(val_set,
grid = expand_grid(mtry = 1:10),
control = control_grid(save_pred = TRUE),
metrics = metric_set(accuracy,roc_auc,recall,spec))
rf_tuning2 <- rf_res2 |>
collect_metrics() |>
group_by(.metric)|>
summarise(max = max(mean),min=min(mean))
rf_tuning2
#plot
rf_plot2 <-
rf_res2 %>%
collect_metrics() %>%
mutate(.metric = ifelse(.metric == "recall","spec",
ifelse(.metric == "spec","recall",
.metric))) %>%
ggplot(aes(x = mtry, y = mean,col=.metric)) +
geom_point() +
geom_line() +
ylab("") +
theme_minimal()+
labs(title = paste0("Etapa 2\nFijado min_n = ", rf_best1$min_n, " se ajusta mtry"))
# Mejor modelo
rf_best2 <-
rf_res2 %>%
select_best(metric = "spec")
rf_best2
rf_plot2
rf_best2
rf_metrics2 <- rf_res2 |>
collect_predictions(parameters = rf_best2) |>
get_metrics()
rf_metrics2
# Plots
ggarrange(rf_plot1,rf_plot2,nrow=1,common.legend = T,legend = "bottom")
rf_res1 <-
rf_workflow1 %>%
tune_grid(val_set,
grid = expand_grid(min_n = seq(500,2500,100)),
control = control_grid(save_pred = TRUE),
metrics = metric_set(accuracy,roc_auc,recall,spec))
rf_tuning1 <- rf_res1 |>
collect_metrics() |>
group_by(.metric)|>
summarise(max = max(mean),min=min(mean))
rf_tuning1
rf_plot1 <-
rf_res1 %>%
collect_metrics() %>%
mutate(.metric = ifelse(.metric == "recall","spec",
ifelse(.metric == "spec","recall",
.metric))) %>%
ggplot(aes(x = min_n, y = mean,col=.metric)) +
geom_point() +
geom_line() +
ylab("") +
theme_minimal()+
labs(title = "Etapa 1\nFijado mtry = 4, se ajusta min_n")
# Mejor modelo
rf_best1 <-
rf_res1 %>%
select_best(metric = "spec")
rf_best1
rf_metrics1 <- rf_res1 |>
collect_predictions(parameters = rf_best1) |>
get_metrics()
# Detectar el número de núcleos para trabajar en paralelo
cores <- parallel::detectCores()
cores
# 1º Construir el modelo
rf_mod1 <-
rand_forest(mtry = 4, min_n = tune(), trees = 1000) %>%
set_engine("ranger", num.threads = cores) %>%
set_mode("classification")
# 2º Construir la receta con el preprocesamiento
rf_recipe <-
recipe(fire ~ ., data = training) %>%
step_date(date,features = c("dow", "month")) %>%
# step_holiday(date) %>%
step_rm(date, cod_municipio, municipio)
# 3º Ensamblar todo con workflow
rf_workflow1 <-
workflow() %>%
add_model(rf_mod1) %>%
add_recipe(rf_recipe)
# 4º Train and tune
set.seed(345)
rf_res1 <-
rf_workflow1 %>%
tune_grid(val_set,
grid = expand_grid(min_n = seq(500,2500,100)),
control = control_grid(save_pred = TRUE),
metrics = metric_set(accuracy,roc_auc,recall,spec))
rf_tuning1 <- rf_res1 |>
collect_metrics() |>
group_by(.metric)|>
summarise(max = max(mean),min=min(mean))
rf_tuning1
rf_plot1 <-
rf_res1 %>%
collect_metrics() %>%
mutate(.metric = ifelse(.metric == "recall","spec",
ifelse(.metric == "spec","recall",
.metric))) %>%
ggplot(aes(x = min_n, y = mean,col=.metric)) +
geom_point() +
geom_line() +
ylab("") +
theme_minimal()+
labs(title = "Etapa 1\nFijado mtry = 4, se ajusta min_n")
# Mejor modelo
rf_best1 <-
rf_res1 %>%
select_best(metric = "spec")
rf_best1
rf_metrics1 <- rf_res1 |>
collect_predictions(parameters = rf_best1) |>
get_metrics()
rf_metrics1
# 1º Se construye el modelo
rf_mod2 <-
rand_forest(mtry = tune(), min_n = rf_best1$min_n, trees = 1000) %>%
set_engine("ranger", num.threads = cores) %>%
set_mode("classification")
# 3º Ensamblar todo con workflow
rf_workflow2 <-
workflow() %>%
add_model(rf_mod2) %>%
add_recipe(rf_recipe)
# 4º Train and tune
set.seed(345)
rf_res2 <-
rf_workflow2 %>%
tune_grid(val_set,
grid = expand_grid(mtry = 1:10),
control = control_grid(save_pred = TRUE),
metrics = metric_set(accuracy,roc_auc,recall,spec))
rf_tuning2 <- rf_res2 |>
collect_metrics() |>
group_by(.metric)|>
summarise(max = max(mean),min=min(mean))
rf_tuning2
#plot
rf_plot2 <-
rf_res2 %>%
collect_metrics() %>%
mutate(.metric = ifelse(.metric == "recall","spec",
ifelse(.metric == "spec","recall",
.metric))) %>%
ggplot(aes(x = mtry, y = mean,col=.metric)) +
geom_point() +
geom_line() +
ylab("") +
theme_minimal()+
labs(title = paste0("Etapa 2\nFijado min_n = ", rf_best1$min_n, " se ajusta mtry"))
rf_plot2
# Mejor modelo
rf_best2 <-
rf_res2 %>%
select_best(metric = "spec")
rf_best2
rf_metrics2 <- rf_res2 |>
collect_predictions(parameters = rf_best2) |>
get_metrics()
rf_metrics2
# Plots
ggarrange(rf_plot1,rf_plot2,nrow=1,common.legend = T,legend = "bottom")
models = tibble(model_name = c("lr","rf"),
models_tune = list(lr_res,rf_res2),
models_workflow = list(lr_workflow,rf_workflow2))
models = models %>% mutate(best_tuning = map(models_tune,function(x) select_best(x,metric = "accuracy")),
best_metrics = map2(models_tune,
best_tuning,
~ collect_predictions(.x,parameters = .y) %>%
get_metrics() %>%
extract2(1)), # Para extraer solo las medidas y no la matriz de confusión
roc = map2(models_tune,
best_tuning,
~ collect_predictions(.x,parameters = .y) %>%
roc_curve(fire, .pred_0))
)
metrics = models %>% select(model_name,best_metrics) %>% unnest(best_metrics)
metrics
# curva roc
metrics %>%
pivot_longer(cols = c(roc_auc, accuracy, recall, specificity, precision),
names_to = "metric") %>%
ggplot(aes(x = metric, y = value, group = model_name)) +
geom_line(aes(col = model_name),size=1) +
geom_point(aes(col = model_name),size=2.3) +
scale_color_viridis_d(option="turbo") +
geom_vline(xintercept=1:5, linetype="dotted") +
labs(col = "Modelo", title = "Métricas sobre validación") +
theme_minimal() +
theme(axis.line.x = element_line(color="black", size = 1),
axis.line.y = element_line(color="black", size = 1))
# plot medidas
models %>% select(model_name,roc) %>% unnest(roc) %>%
ggplot(aes(x = 1 - specificity, y = sensitivity, col = model_name)) +
geom_path(lwd = 1, alpha = 0.7) +
geom_abline(lty = 3) +
coord_equal() +
scale_color_viridis_d(option="turbo") +
labs(color="Modelo")+
# scale_color_viridis_d(option = "turbo",name="Modelo") +
theme_minimal() +
theme(axis.line.x = element_line(color="black", size = 1),
axis.line.y = element_line(color="black", size = 1))+
ggtitle("Curva ROC en validación")
library(knitr)
kable(metrics,digits=3)
cores = 8
set.seed(345)
models <- models %>% mutate(final_workflow = map2(models_workflow,best_tuning,finalize_workflow),
last_fit = map(final_workflow,function(x) last_fit(x,splits,add_validation_set=T)))
models = models %>% mutate(test_metrics = map(last_fit,
~collect_predictions(.x) %>%
get_metrics() %>%
extract2(1)), # Para extraer solo las medidas
test_roc = map(last_fit,
~collect_predictions(.x) %>%
roc_curve(fire, .pred_0))
)
test_metrics = models %>% select(model_name,test_metrics) %>% unnest(test_metrics)
test_metrics
# plot
test_metrics %>%
pivot_longer(cols = c(roc_auc, accuracy, recall, specificity, precision),
names_to = "metric") %>%
ggplot(aes(x = metric, y = value, group = model_name)) +
geom_line(aes(col = model_name),size=1) +
geom_point(aes(col = model_name),size=2.3) +
scale_color_viridis_d(option="turbo") +
geom_vline(xintercept=1:5, linetype="dotted") +
labs(col = "Modelo", title = "Métricas sobre test") +
theme_minimal() +
theme(axis.line.x = element_line(color="black", size = 1),
axis.line.y = element_line(color="black", size = 1))
models %>% select(model_name,test_roc) %>% unnest(test_roc) %>%
ggplot(aes(x = 1 - specificity, y = sensitivity, col = model_name)) +
geom_path(lwd = 1, alpha = 0.7) +
geom_abline(lty = 3) +
coord_equal() +
scale_color_viridis_d(option="turbo") +
labs(color="Modelo")+
# scale_color_viridis_d(option = "turbo",name="Modelo") +
theme_minimal() +
theme(axis.line.x = element_line(color="black", size = 1),
axis.line.y = element_line(color="black", size = 1))+
ggtitle("Curva ROC en test")
library(knitr)
kable(test_metrics,digits=3)
# the last model
last_rf_mod <-
rand_forest(mtry = rf_best2$mtry, min_n = rf_best1$min_n, trees = 1000) %>%
set_engine("ranger", num.threads = cores,importance="impurity") %>%
set_mode("classification")
# the last workflow
last_rf_workflow <-
rf_workflow2 %>%
update_model(last_rf_mod)
# the last fit
set.seed(345)
last_rf_fit <-
last_rf_workflow %>%
last_fit(splits,
add_validation_set = T)
library(vip)
last_rf_fit %>%
extract_fit_parsnip() %>%
vip(num_features = 50,aesthetics = list(fill="lightblue")) +
theme_minimal()
# model <- models %>% filter(model_name=="lr")
# model <- models %>% filter(model_name=="svm_linear")
model <- models %>% filter(model_name=="rf")
pred_class = model %>%
pull(last_fit) %>%
.[[1]] %>%
extract_workflow() %>%
predict(new_data = full_grid)
pred_probs = model %>%
pull(last_fit) %>%
.[[1]] %>%
extract_workflow() %>%
predict(new_data = full_grid,type="prob")
pred = cbind(full_grid,pred_class,pred_probs)
g <- ggplot(data = and) +
geom_sf() +
geom_sf(data = pred, aes(color=.pred_1, alpha = .pred_1),size = 1.5) +
facet_wrap(~month(date,label=TRUE)) +
scale_color_gradientn(colours = rainbow(5,rev=T),limits=c(0,1)) +
# scale_color_gradient(low="blue", high="red")+
labs(title="Probabilidad estimada de incendio el día 15 de cada mes de 2022",
subtitle = paste0("Model: ",model$model_name)) +
guides(alpha = "none") +
theme_minimal() +
theme(axis.text.x=element_blank(),
axis.ticks.x=element_blank(),
axis.text.y=element_blank(),
axis.ticks.y=element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank())
g
# OPCIÓN 1 (mejor)
ggplot(data = and) +
geom_sf() +
geom_sf(data = pred, aes(color=.pred_1),alpha=0.8,size = 1.5) +
facet_wrap(~month(date,label=TRUE)) +
scale_color_gradientn(colours = rainbow(5,rev=T),limits=c(0,1)) +
# scale_color_gradient(low="blue", high="red")+
guides(alpha = "none") +
theme_minimal() +
theme(axis.text.x=element_blank(),
axis.ticks.x=element_blank(),
axis.text.y=element_blank(),
axis.ticks.y=element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank()) +
geom_sf(data = incendios22 %>% st_centroid, color = "black", shape =24, size=1,fill = "red") +
labs(title = "Probabilidad de incendio estimada el día 15 de cada mes de 2022",
subtitle = paste0("Modelo: ",model$model_name),
color = "Probalidad\nde incendio\nestimada")
temp05 <- full_grid %>%
mutate(T2M = 1.05*T2M)
pred_class_temp05 = lr_final %>%
pull(last_fit) %>%
.[[1]] %>%
extract_workflow() %>%
predict(new_data = temp05)
pred_probs_temp05 = lr_final %>%
pull(last_fit) %>%
.[[1]] %>%
extract_workflow() %>%
predict(new_data = temp05,type="prob")
pred_temp05 = cbind(full_grid,pred_class_temp05,pred_probs_temp05)
temp05 <- full_grid %>%
mutate(T2M = 1.05*T2M)
pred_class_temp05 = lr_final %>%
pull(last_fit) %>%
.[[1]] %>%
extract_workflow() %>%
predict(new_data = temp05)
incendios21 <- st_read(paste0("./data_raw/incendios_2000-2022/incendios_",2021,".shp")) %>%
st_transform(st_crs(datos)) %>%
mutate(FECHA_INIC=ymd(FECHA_INIC))
incendio_estudio <- incendios21 %>% filter(month(FECHA_INIC)==9)
and <- esp_get_ccaa(ccaa = "Andalucía") %>% st_transform(st_crs(datos))
rm(incendios21)
prov <- esp_get_prov() %>% filter(nuts2.name=="Andalucía") %>% st_transform(st_crs(datos))
bbox = st_buffer(incendio_estudio,dist=10000) %>%
st_bbox()
# save(full_grid,file = "salidas_intermedias/full_grid_incendio_0921_processed.RData")
load("salidas_intermedias/full_grid_incendio_0921_processed.RData")
# model <- models %>% filter(model_name=="lr")
# model <- models %>% filter(model_name=="svm_rbf")
# model <- models %>% filter(model_name=="svm_linear")
model <- models %>% filter(model_name=="rf")
pred_class = model %>%
pull(last_fit) %>%
.[[1]] %>%
extract_workflow() %>%
predict(new_data = full_grid)
pred_probs = model %>%
pull(last_fit) %>%
.[[1]] %>%
extract_workflow() %>%
predict(new_data = full_grid,type="prob")
pred = cbind(full_grid,pred_class,pred_probs)
g <- ggplot(data = and) +
geom_sf() +
geom_sf(data = pred, aes(color=.pred_1, alpha = .pred_1),size = 1.5) +
facet_wrap(~date) +
scale_color_gradientn(colours = rainbow(5,rev=T),limits=c(0,1)) +
# scale_color_gradient(low="blue", high="red")+
labs(title="Incendio de Sierra Bermeja",
subtitle = paste0("Model: ",model$model_name)) +
guides(alpha = "none") +
theme_minimal() +
theme(axis.text.x=element_blank(),
axis.ticks.x=element_blank(),
axis.text.y=element_blank(),
axis.ticks.y=element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank()) +
geom_sf(data = incendio_estudio, fill="transparent",col="red") +
labs(color = "Probabilidad\nestimada de\nincendio") +
coord_sf(xlim=c(bbox$xmin,bbox$xmax),ylim=c(bbox$ymin,bbox$ymax))
g
model <- models %>% filter(model_name=="lr")
pred_class = model %>%
pull(last_fit) %>%
.[[1]] %>%
extract_workflow() %>%
predict(new_data = full_grid)
pred_probs = model %>%
pull(last_fit) %>%
.[[1]] %>%
extract_workflow() %>%
predict(new_data = full_grid,type="prob")
pred = cbind(full_grid,pred_class,pred_probs)
g <- ggplot(data = and) +
geom_sf() +
geom_sf(data = pred, aes(color=.pred_1, alpha = .pred_1),size = 1.5) +
facet_wrap(~date) +
scale_color_gradientn(colours = rainbow(5,rev=T),limits=c(0,1)) +
# scale_color_gradient(low="blue", high="red")+
labs(title="Incendio de Sierra Bermeja",
subtitle = paste0("Model: ",model$model_name)) +
guides(alpha = "none") +
theme_minimal() +
theme(axis.text.x=element_blank(),
axis.ticks.x=element_blank(),
axis.text.y=element_blank(),
axis.ticks.y=element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank()) +
geom_sf(data = incendio_estudio, fill="transparent",col="red") +
labs(color = "Probabilidad\nestimada de\nincendio") +
coord_sf(xlim=c(bbox$xmin,bbox$xmax),ylim=c(bbox$ymin,bbox$ymax))
g
lr_workflow %>%
finalize_workflow(lr_best) %>%
fit(training) %>%
extract_fit_parsnip() %>%
tidy() %>% print(n=100)
last_rf_fit %>%
extract_fit_parsnip() %>%
vip(num_features = 50,aesthetics = list(fill="lightblue")) +
theme_minimal()
kable(test_metrics,digits=3)
load("salidas_intermedias/dataset_strat_completo2024-04-26.RData")
str(dataset)
dim(datos)
View(full_grid)
names(datos)
load("salidas_intermedias/datos_strat_depurados_geom_2024-05-03.RData")
datos
names(datos)
dim(datos)
library(stringr)
library(stringr)
str_count("A pesar de la importancia de la meteorología en los incendios, la capacidad predictiva de la ocurrencia de incendios [...] en base a variables meteorológicas [...] suele ser baja. [...] Esto es debido a que la mayor aprte de los incendios en España es de de origen humano, lo que dificulta su predictibilidad. Así, las igniciones no ocurren al azar, ni en el espacio ni en el tiempo. [...] El territorio no se quema de manera aleatoria, siendo normal que unas zonas ardan más que otras.")
a = "A pesar de la importancia de la meteorología en los incendios, la capacidad predictiva de la ocurrencia de incendios [...] en base a variables meteorológicas [...] suele ser baja. [...] Esto es debido a que la mayor aprte de los incendios en España es de de origen humano, lo que dificulta su predictibilidad. Así, las igniciones no ocurren al azar, ni en el espacio ni en el tiempo. [...] El territorio no se quema de manera aleatoria, siendo normal que unas zonas ardan más que otras."
str_split(a)
str_split(a,"\\w")
str_split(a,"\\b")
str_split(a,boundary("word"))
str_split(a,boundary("word")) |> count()
str_split(a,boundary("word")) |> length
str_split(a,boundary("word")) |> length()
