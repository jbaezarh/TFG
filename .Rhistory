datos |> st_drop_geometry() |> filter(is.na(NDVI)) |> count()
datos |> st_drop_geometry() |> filter(is.na(NDVI)) |> count()
datos %<>% filter(!is.na(NDVI))
datos
summary(datos)
datos %<>% filter(!is.na(poblacion))
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Librerías:
library(tidyverse)
library(sf)
library(terra)
library(mapSpain)
library(magrittr)
# Chunk 2
load("salidas_intermedias/dataset_completo2024-03-27.RData")
datos = dataset |>
select(-c(YEAR,MM,DD))
# Chunk 3
str(datos)
# Chunk 4
summary(datos)
# Chunk 5
datos <- datos |>
mutate(fire = as.factor(fire),
enp = as.factor(enp),
uso_suelo = as.factor(uso_suelo))
# Chunk 6
datos = datos |>
mutate(orientacion = cut(orientacion,
breaks = c(-Inf,-1,22.5,67.5,112.5,157.5,202.5,247.5,292.5,337.5,360),
labels = c("Plano","N","NE","E","SE","S","SW","W","NW","N")))
# Chunk 7
summary(datos)
# Chunk 8
Andalucia <- esp_get_ccaa(ccaa = "Andalucía")
andalucia_proj <- st_transform(Andalucia,st_crs(dataset))
plot(st_geometry(andalucia_proj),reset=F)
datos |>
filter(is.na(pendiente)| is.na(orientacion) | is.na(curvatura)) |>
st_geometry() |>
plot(pch=16,col="red",add=T)
datos |>
st_drop_geometry() |>
filter(is.na(pendiente)| is.na(orientacion) | is.na(curvatura)) |>
count() #53 observaciones NA
# Chunk 9
datos = datos |>
filter(!(is.na(pendiente)| is.na(orientacion) | is.na(curvatura)))
summary(datos)
# Chunk 10
datos |>
st_drop_geometry() |>
filter(is.na(poblacion)) |>
mutate(Año = year(date)) |>
select(Año,municipio,cod_municipio)
# Chunk 11
pob = read_csv2("D:/usuario/Documents/Universidad/5º/TFG - organizado/data_raw/antropologicas/Población/poblacion_municipios.txt")[,c(1:5)]
pob |> filter(CODIGO_INE3 == "18077")
# Chunk 12
datos %<>% filter(!is.na(poblacion))
# Chunk 13
plot(st_geometry(andalucia_proj),reset=F)
datos |> filter(is.na(uso_suelo)) |> st_geometry() |> plot(pch=16,col="red",add=T)
datos = datos |>
filter(!is.na(uso_suelo))
# Chunk 14
NDVI_mes = datos |>
st_drop_geometry() |>
mutate(mes = month(date),
año = year(date)) |>
group_by(año,mes) |>
summarise(NDVI_mes = mean(na.omit(NDVI))) |>
ungroup() |>
mutate(date = dmy(paste(01,mes,año,sep="/")))
NDVI_mes |>
ggplot(aes(x=date,y=NDVI_mes)) +
geom_line()+
scale_x_date(date_breaks = "6 month",date_labels = "%y%b")+
theme(axis.text.x = element_text(angle = 90))
# Chunk 15
datos |>
st_drop_geometry() |>
filter(year(date) %in% 2000:2001) |>
count()
# Chunk 16
datos %<>% filter(!year(date) %in% 2000:2001)
# Chunk 17
# La siguiente función lee el archivo con el NDVI corresponfiente a un mes y a un año dados (si está disponible)
read_NDVI = function(MM,YYYY) {
MM = str_pad(as.character(MM),2,"left",pad = "0")
YY = substr(as.character(YYYY),3,4)
if (as.numeric(YY)<=06) {
ruta <- paste0("data_raw/vegetacion/",YYYY,"TERMODMEDMNDVI/InfGeografica/InfRaster/TIFF/TERMOD_",YY,MM,"01_h17v05_medmndvi.tif")
} else if (as.numeric(YY)<=11) {
ruta <- paste0("data_raw/vegetacion/",YYYY,"TERMODMEDMNDVI/InfGeografica/InfRaster/TIF/TERMOD_",YY,MM,"01_h17v05_medmndvi.tif")
} else if (as.numeric(YY)<=21){
ruta <- paste0("data_raw/vegetacion/",YYYY,"TERMODMEDMNDVI/InfGeografica/InfRaster/TIFF/termod_",YY,MM,"01_h17v05_medmndvi.tif")
}else {
ruta <- paste0("data_raw/vegetacion/",YYYY,"TERMODMEDMNDVI/InfGeografica/InfRaster/COG/termod_",YY,MM,"01_h17v05_medmndvi_COG.tif")
}
if (file.exists(ruta)) {
NDVI = rast(ruta)
} else
NDVI = NA
return(NDVI)
}
# Los meses para los cuales no está disponible el NDVI:
year_month_missing_NDVI = c(
"2003-01",
"2003-04",
"2017-02",
"2018-11",
"2020-11",
"2021-12",
"2022-03",
"2022-12")
# Para cada observación para la que no está disponible el NDVI (porque la información de ese mes no está disponible), se obtiene el correspondiente al mismo mes del año anterior, si este está disponible, si no, el del año posterior:
missing_NDVI = datos |>
filter(is.na(NDVI)) |>
mutate(year = year(date),month = month(date)) |>
group_by(year,month) |>
filter(paste(year,str_pad(as.character(month),2,"left",pad = "0"),sep="-") %in%   year_month_missing_NDVI) |>  # Se filtra porque también hay observaciones que tienen NA en el NDVI no porque no exista el archivo, si no lo mismo que en ocasiones anteriores, porques discrepancias entre los límites de los polígonos
nest() |>
mutate(NDVI_rast = map2(month,year-1,read_NDVI), # Se lee primero el del año anterior
NDVI_rast = ifelse(is.na(unlist(NDVI_rast)),map2(month,year+1,read_NDVI),NDVI_rast), # Si no está disponible, se toma el del año posterior
NDVI_nuevo = map2(NDVI_rast,data,~terra::extract(.x,.y)[,2])) |>
select(-NDVI_rast) |>
unnest(c(data,NDVI_nuevo)) |>
mutate(NDVI = NDVI_nuevo,.keep="unused")
ind_modificados = is.na(datos$NDVI) & (paste(year(datos$date),str_pad(as.character(month(datos$date)),2,"left",pad = "0"),sep="-") %in% year_month_missing_NDVI) # Los elementos que han sido modificados
# Se asignan los valores imputados del NDVI:
datos[ind_modificados,]$NDVI = missing_NDVI$NDVI
summary(datos)
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Librerías:
library(tidyverse)
library(sf)
library(terra)
library(mapSpain)
library(magrittr)
# Chunk 2
load("salidas_intermedias/dataset_completo2024-03-27.RData")
datos = dataset |>
select(-c(YEAR,MM,DD))
# Chunk 3
str(datos)
# Chunk 4
summary(datos)
# Chunk 5
datos <- datos |>
mutate(fire = as.factor(fire),
enp = as.factor(enp),
uso_suelo = as.factor(uso_suelo))
# Chunk 6
datos = datos |>
mutate(orientacion = cut(orientacion,
breaks = c(-Inf,-1,22.5,67.5,112.5,157.5,202.5,247.5,292.5,337.5,360),
labels = c("Plano","N","NE","E","SE","S","SW","W","NW","N")))
# Chunk 7
summary(datos)
# Chunk 8
Andalucia <- esp_get_ccaa(ccaa = "Andalucía")
andalucia_proj <- st_transform(Andalucia,st_crs(dataset))
plot(st_geometry(andalucia_proj),reset=F)
datos |>
filter(is.na(pendiente)| is.na(orientacion) | is.na(curvatura)) |>
st_geometry() |>
plot(pch=16,col="red",add=T)
datos |>
st_drop_geometry() |>
filter(is.na(pendiente)| is.na(orientacion) | is.na(curvatura)) |>
count() #53 observaciones NA
# Chunk 9
datos = datos |>
filter(!(is.na(pendiente)| is.na(orientacion) | is.na(curvatura)))
summary(datos)
# Chunk 10
datos |>
st_drop_geometry() |>
filter(is.na(poblacion)) |>
mutate(Año = year(date)) |>
select(Año,municipio,cod_municipio)
# Chunk 11
pob = read_csv2("D:/usuario/Documents/Universidad/5º/TFG - organizado/data_raw/antropologicas/Población/poblacion_municipios.txt")[,c(1:5)]
pob |> filter(CODIGO_INE3 == "18077")
# Chunk 12
datos %<>% filter(!is.na(poblacion))
# Chunk 13
plot(st_geometry(andalucia_proj),reset=F)
datos |> filter(is.na(uso_suelo)) |> st_geometry() |> plot(pch=16,col="red",add=T)
datos = datos |>
filter(!is.na(uso_suelo))
# Chunk 14
NDVI_mes = datos |>
st_drop_geometry() |>
mutate(mes = month(date),
año = year(date)) |>
group_by(año,mes) |>
summarise(NDVI_mes = mean(na.omit(NDVI))) |>
ungroup() |>
mutate(date = dmy(paste(01,mes,año,sep="/")))
NDVI_mes |>
ggplot(aes(x=date,y=NDVI_mes)) +
geom_line()+
scale_x_date(date_breaks = "6 month",date_labels = "%y%b")+
theme(axis.text.x = element_text(angle = 90))
# Chunk 15
datos |>
st_drop_geometry() |>
filter(year(date) %in% 2000:2001) |>
count()
# Chunk 16
datos %<>% filter(!year(date) %in% 2000:2001)
# Chunk 17
# La siguiente función lee el archivo con el NDVI corresponfiente a un mes y a un año dados (si está disponible)
read_NDVI = function(MM,YYYY) {
MM = str_pad(as.character(MM),2,"left",pad = "0")
YY = substr(as.character(YYYY),3,4)
if (as.numeric(YY)<=06) {
ruta <- paste0("data_raw/vegetacion/",YYYY,"TERMODMEDMNDVI/InfGeografica/InfRaster/TIFF/TERMOD_",YY,MM,"01_h17v05_medmndvi.tif")
} else if (as.numeric(YY)<=11) {
ruta <- paste0("data_raw/vegetacion/",YYYY,"TERMODMEDMNDVI/InfGeografica/InfRaster/TIF/TERMOD_",YY,MM,"01_h17v05_medmndvi.tif")
} else if (as.numeric(YY)<=21){
ruta <- paste0("data_raw/vegetacion/",YYYY,"TERMODMEDMNDVI/InfGeografica/InfRaster/TIFF/termod_",YY,MM,"01_h17v05_medmndvi.tif")
}else {
ruta <- paste0("data_raw/vegetacion/",YYYY,"TERMODMEDMNDVI/InfGeografica/InfRaster/COG/termod_",YY,MM,"01_h17v05_medmndvi_COG.tif")
}
if (file.exists(ruta)) {
NDVI = rast(ruta)
} else
NDVI = NA
return(NDVI)
}
# Los meses para los cuales no está disponible el NDVI:
year_month_missing_NDVI = c(
"2003-01",
"2003-04",
"2017-02",
"2018-11",
"2020-11",
"2021-12",
"2022-03",
"2022-12")
# Para cada observación para la que no está disponible el NDVI (porque la información de ese mes no está disponible), se obtiene el correspondiente al mismo mes del año anterior, si este está disponible, si no, el del año posterior:
missing_NDVI = datos |>
filter(is.na(NDVI)) |>
mutate(year = year(date),month = month(date)) |>
group_by(year,month) |>
filter(paste(year,str_pad(as.character(month),2,"left",pad = "0"),sep="-") %in%   year_month_missing_NDVI) |>  # Se filtra porque también hay observaciones que tienen NA en el NDVI no porque no exista el archivo, si no lo mismo que en ocasiones anteriores, porques discrepancias entre los límites de los polígonos
nest() |>
mutate(NDVI_rast = map2(month,year-1,read_NDVI), # Se lee primero el del año anterior
NDVI_rast = ifelse(is.na(unlist(NDVI_rast)),map2(month,year+1,read_NDVI),NDVI_rast), # Si no está disponible, se toma el del año posterior
NDVI_nuevo = map2(NDVI_rast,data,~terra::extract(.x,.y)[,2])) |>
select(-NDVI_rast) |>
unnest(c(data,NDVI_nuevo)) |>
mutate(NDVI = NDVI_nuevo,.keep="unused")
ind_modificados = is.na(datos$NDVI) & (paste(year(datos$date),str_pad(as.character(month(datos$date)),2,"left",pad = "0"),sep="-") %in% year_month_missing_NDVI) # Los elementos que han sido modificados
# Se asignan los valores imputados del NDVI:
datos[ind_modificados,]$NDVI = missing_NDVI$NDVI
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Librerías:
library(tidyverse)
library(sf)
library(terra)
library(mapSpain)
library(magrittr)
# Chunk 2
load("salidas_intermedias/dataset_completo2024-03-27.RData")
datos = dataset |>
select(-c(YEAR,MM,DD))
# Chunk 3
str(datos)
# Chunk 4
summary(datos)
# Chunk 5
datos <- datos |>
mutate(fire = as.factor(fire),
enp = as.factor(enp),
uso_suelo = as.factor(uso_suelo))
# Chunk 6
datos = datos |>
mutate(orientacion = cut(orientacion,
breaks = c(-Inf,-1,22.5,67.5,112.5,157.5,202.5,247.5,292.5,337.5,360),
labels = c("Plano","N","NE","E","SE","S","SW","W","NW","N")))
# Chunk 7
summary(datos)
# Chunk 8
Andalucia <- esp_get_ccaa(ccaa = "Andalucía")
andalucia_proj <- st_transform(Andalucia,st_crs(dataset))
plot(st_geometry(andalucia_proj),reset=F)
datos |>
filter(is.na(pendiente)| is.na(orientacion) | is.na(curvatura)) |>
st_geometry() |>
plot(pch=16,col="red",add=T)
datos |>
st_drop_geometry() |>
filter(is.na(pendiente)| is.na(orientacion) | is.na(curvatura)) |>
count() #53 observaciones NA
# Chunk 9
datos = datos |>
filter(!(is.na(pendiente)| is.na(orientacion) | is.na(curvatura)))
summary(datos)
# Chunk 10
datos |>
st_drop_geometry() |>
filter(is.na(poblacion)) |>
mutate(Año = year(date)) |>
select(Año,municipio,cod_municipio)
# Chunk 11
pob = read_csv2("D:/usuario/Documents/Universidad/5º/TFG - organizado/data_raw/antropologicas/Población/poblacion_municipios.txt")[,c(1:5)]
pob |> filter(CODIGO_INE3 == "18077")
# Chunk 12
datos %<>% filter(!is.na(poblacion))
# Chunk 13
plot(st_geometry(andalucia_proj),reset=F)
datos |> filter(is.na(uso_suelo)) |> st_geometry() |> plot(pch=16,col="red",add=T)
datos = datos |>
filter(!is.na(uso_suelo))
# Chunk 14
NDVI_mes = datos |>
st_drop_geometry() |>
mutate(mes = month(date),
año = year(date)) |>
group_by(año,mes) |>
summarise(NDVI_mes = mean(na.omit(NDVI))) |>
ungroup() |>
mutate(date = dmy(paste(01,mes,año,sep="/")))
NDVI_mes |>
ggplot(aes(x=date,y=NDVI_mes)) +
geom_line()+
scale_x_date(date_breaks = "6 month",date_labels = "%y%b")+
theme(axis.text.x = element_text(angle = 90))
# Chunk 15
datos |>
st_drop_geometry() |>
filter(year(date) %in% 2000:2001) |>
count()
# Chunk 16
datos %<>% filter(!year(date) %in% 2000:2001)
# Chunk 17
# La siguiente función lee el archivo con el NDVI corresponfiente a un mes y a un año dados (si está disponible)
read_NDVI = function(MM,YYYY) {
MM = str_pad(as.character(MM),2,"left",pad = "0")
YY = substr(as.character(YYYY),3,4)
if (as.numeric(YY)<=06) {
ruta <- paste0("data_raw/vegetacion/",YYYY,"TERMODMEDMNDVI/InfGeografica/InfRaster/TIFF/TERMOD_",YY,MM,"01_h17v05_medmndvi.tif")
} else if (as.numeric(YY)<=11) {
ruta <- paste0("data_raw/vegetacion/",YYYY,"TERMODMEDMNDVI/InfGeografica/InfRaster/TIF/TERMOD_",YY,MM,"01_h17v05_medmndvi.tif")
} else if (as.numeric(YY)<=21){
ruta <- paste0("data_raw/vegetacion/",YYYY,"TERMODMEDMNDVI/InfGeografica/InfRaster/TIFF/termod_",YY,MM,"01_h17v05_medmndvi.tif")
}else {
ruta <- paste0("data_raw/vegetacion/",YYYY,"TERMODMEDMNDVI/InfGeografica/InfRaster/COG/termod_",YY,MM,"01_h17v05_medmndvi_COG.tif")
}
if (file.exists(ruta)) {
NDVI = rast(ruta)
} else
NDVI = NA
return(NDVI)
}
# Los meses para los cuales no está disponible el NDVI:
year_month_missing_NDVI = c(
"2003-01",
"2003-04",
"2017-02",
"2018-11",
"2020-11",
"2021-12",
"2022-03",
"2022-12")
# Para cada observación para la que no está disponible el NDVI (porque la información de ese mes no está disponible), se obtiene el correspondiente al mismo mes del año anterior, si este está disponible, si no, el del año posterior:
missing_NDVI = datos |>
filter(is.na(NDVI)) |>
mutate(year = year(date),month = month(date)) |>
group_by(year,month) |>
filter(paste(year,str_pad(as.character(month),2,"left",pad = "0"),sep="-") %in%   year_month_missing_NDVI) |>  # Se filtra porque también hay observaciones que tienen NA en el NDVI no porque no exista el archivo, si no lo mismo que en ocasiones anteriores, porques discrepancias entre los límites de los polígonos
nest() |>
mutate(NDVI_rast = map2(month,year-1,read_NDVI), # Se lee primero el del año anterior
NDVI_rast = ifelse(is.na(unlist(NDVI_rast)),map2(month,year+1,read_NDVI),NDVI_rast), # Si no está disponible, se toma el del año posterior
NDVI_nuevo = map2(NDVI_rast,data,~terra::extract(.x,.y)[,2])) |>
select(-NDVI_rast) |>
unnest(c(data,NDVI_nuevo)) |>
mutate(NDVI = NDVI_nuevo,.keep="unused")
ind_modificados = is.na(datos$NDVI) & (paste(year(datos$date),str_pad(as.character(month(datos$date)),2,"left",pad = "0"),sep="-") %in% year_month_missing_NDVI) # Los elementos que han sido modificados
# Se asignan los valores imputados del NDVI:
datos[ind_modificados,]$NDVI = missing_NDVI$NDVI
# Chunk 18
datos |> st_drop_geometry() |> filter(is.na(NDVI)) |> count() # 16
datos %<>% filter(!is.na(NDVI))
summary(datos)
paste0("salidas_intermedias/datos_depurados",Sys.Date(),".RData")
save(datos, file = paste0("salidas_intermedias/datos_depurados",Sys.Date(),".RData"))
tfe_principal.log
tinytex::uninstall_tinytex()
tinytex::is_tinytex()
remove.packages(tinytex)
remove.packages("tinytex")
install.packages("tinytex")
install.packages("tinytex")
tinytex::install_tinytex()
renv::init()
install.packages(reenv)
install.packages("reenv")
install.packages("renv")
library(renv)
renv::init()
.libPaths()
getOption("repos")
setwd("D:/usuario/Documents/Universidad/5º/TFG - organizado")
load("salidas_intermedias/dataset_completo2024-03-27.RData")
datos = dataset |>
select(-c(YEAR,MM,DD))
# Librerías:
library(tidyverse)
library(sf)
library(terra)
library(mapSpain)
library(magrittr)
load("salidas_intermedias/dataset_completo2024-03-27.RData")
datos = dataset |>
select(-c(YEAR,MM,DD))
str(datos)
library(tidyverse)
library(skimr)
library(sf)
library(corrplot)
load("salidas_intermedias/datos_depurados2024-03-30.RData")
datos <- datos |>
mutate(uso_suelo = uso_suelo |>
as.character() |>
str_sub(2) |>
as.factor()) |>
st_drop_geometry()
datos_numeric = datos |> select(is.numeric)
library(cluster)
clara<- clara(datos,2)
tabla(clara$clustering,datos$fire)
table(clara$clustering,datos$fire)
table(clara$clustering)
clara<- clara(datos,2)
table(clara$clustering)
clara<- clara(datos,2)
table(clara$clustering)
pca <- princomp(datos_numeric,cor=T)
summary(pca)
clara<- clara(datos,2)
table(clara$clustering)
?clara
clara<- clara(datos_numeric,2)
table(clara$clustering)
library(cluster)
clara<- clara(datos_numeric,2)
table(clara$clustering)
clara<- clara(datos_numeric,metric="euclidean",2)
table(clara$clustering)
library(cluster)
clara<- clara(datos,2)
table(clara$clustering)
datos_num_scaled = scale(datos, center=T,scale=T)
datos_num_scaled = scale(datos_numeric, center=T,scale=T)
clara<- clara(datos_numeric,2)
table(clara$clustering)
View(datos_num_scaled)
clara<- clara(datos_num_scaled,2)
table(clara$clustering)
clara = datos_numeric |>
scale |>
clara(k=2)
clara = datos_numeric |>
scale() |>
clara(k=2)
table(clara$clustering)
table(clara$clustering,datos$fire)
# Ahora el algoritmo consigue separar mejor los datos
table(clara$clustering,datos$fire)
# Ahora el algoritmo consigue separar mejor los datos
table(clara$clustering,datos$fire) |> diag()
# Ahora el algoritmo consigue separar mejor los datos
table(clara$clustering,datos$fire)
rbind(table(clara$clustering,datos$fire)[2,],
able(clara$clustering,datos$fire)[1,])
rbind(table(clara$clustering,datos$fire)[2,],
table(clara$clustering,datos$fire)[1,])
?pam
rbind(cluster_1 =t[2,],
t[1,])
rbind(t[2,],
t[1,])
t = table(clara$clustering,datos$fire)
rbind(t[2,],
t[1,])
rbind(cluster_1=t[2,],
t[1,])
t = rbind(t[2,],t[1,])
rownames(t) <- c(1,2)
rownames(t) <- paste0("cluster_",c(1,2))
colnames(t) <- levels(datos$fire)
t
colnames(t) <- c("No fire","Fire")
t
addmargins(t)
addmargins(t,)
?addmargins
addmargins(t)
prop.table(t,2)
t
prop.table(t,2)
prop.table(t,2)*100
mean(diag(t))
sum(diag(t))/nrow(datos)
